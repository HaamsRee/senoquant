{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SenoQuant Documentation","text":""},{"location":"#about","title":"About","text":"<p>SenoQuant is a versatile napari plugin designed for comprehensive, accurate, and unbiased spatial quantification and prediction of senescence markers across diverse tissue contexts.</p> <p>Use these docs to:</p> <ul> <li>Install the plugin and its optional components.</li> <li>Learn the user workflow for each tab.</li> <li>Understand how models, detectors, and quantification features are wired.</li> <li>Add or extend prediction models for senescence-associated feature maps.</li> <li>Contribute new models, detectors, or features.</li> </ul> <p>Start here:</p> <ul> <li>User Guide: <code>Installation</code> and <code>Quick Start</code>.</li> <li>User Guide: <code>Prediction</code>.</li> <li>Developer Guide: <code>Architecture</code>, <code>Models &amp; Detectors</code>, and <code>Prediction Models</code>.</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This page is generated automatically from docstrings using <code>mkdocstrings</code>.</p>"},{"location":"api/#package-overview","title":"Package Overview","text":"<p>SenoQuant napari plugin package.</p>"},{"location":"api/#core-components","title":"Core Components","text":""},{"location":"api/#main-widget","title":"Main Widget","text":"<p>               Bases: <code>QWidget</code></p> <p>Main SenoQuant widget with tabbed UI.</p>"},{"location":"api/#utilities","title":"Utilities","text":"<p>Utility package exports.</p>"},{"location":"api/#senoquant.utils.append_run_metadata","title":"<code>append_run_metadata(metadata, *, task, runner_type, runner_name, settings=None)</code>","text":"<p>Append a timestamped run entry to layer metadata.</p>"},{"location":"api/#senoquant.utils.append_run_metadata--parameters","title":"Parameters","text":"<p>metadata : dict or None     Existing layer metadata. task : str     Task name (for example <code>\"nuclear\"</code>). runner_type : str     Run source type (for example <code>\"segmentation_model\"</code>). runner_name : str     Model or detector name used for the run. settings : dict or None, optional     Settings used for the run.</p>"},{"location":"api/#senoquant.utils.append_run_metadata--returns","title":"Returns","text":"<p>dict     Updated metadata dictionary containing <code>task</code> and <code>run_history</code>.</p>"},{"location":"api/#senoquant.utils.labels_data_as_dask","title":"<code>labels_data_as_dask(data)</code>","text":"<p>Wrap label data in a chunked dask array when possible.</p>"},{"location":"api/#senoquant.utils.labels_data_as_dask--parameters","title":"Parameters","text":"<p>data : array-like     Label data to present in napari.</p>"},{"location":"api/#senoquant.utils.labels_data_as_dask--returns","title":"Returns","text":"<p>array-like     Dask-backed array when conversion succeeds, otherwise the original     array-like input.</p>"},{"location":"api/#senoquant.utils.layer_data_asarray","title":"<code>layer_data_asarray(layer, *, squeeze=True)</code>","text":"<p>Return layer data as a NumPy array, optionally squeezed.</p>"},{"location":"api/#senoquant.utils.layer_data_asarray--parameters","title":"Parameters","text":"<p>layer : object     napari layer instance providing a <code>data</code> attribute. squeeze : bool, optional     Whether to remove singleton dimensions.</p>"},{"location":"api/#senoquant.utils.layer_data_asarray--returns","title":"Returns","text":"<p>numpy.ndarray     Array representation of the layer data.</p>"},{"location":"api/#reader","title":"Reader","text":"<p>Core BioIO reader implementation for SenoQuant.</p>"},{"location":"api/#senoquant.reader.core.get_reader","title":"<code>get_reader(path)</code>","text":"<p>Return a reader callable for the given path.</p>"},{"location":"api/#senoquant.reader.core.get_reader--parameters","title":"Parameters","text":"<p>path : str or list of str     Path(s) selected in the napari reader dialog.</p>"},{"location":"api/#senoquant.reader.core.get_reader--returns","title":"Returns","text":"<p>callable or None     Reader callable that returns napari layer data, or <code>None</code> if the     path is not supported.</p>"},{"location":"api/#senoquant.reader.core.get_reader--notes","title":"Notes","text":"<p>This uses <code>bioio.BioImage.determine_plugin</code> to ensure the file can be handled by BioIO. If the file is unsupported or BioIO is unavailable, <code>None</code> is returned so napari can try other readers.</p>"},{"location":"api/#segmentation","title":"Segmentation","text":""},{"location":"api/#backend","title":"Backend","text":"<p>Backend logic for the Segmentation tab.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend","title":"<code>SegmentationBackend</code>","text":"<p>Manage segmentation models and their storage locations.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend--parameters","title":"Parameters","text":"<p>models_root : pathlib.Path or None     Optional root folder for model storage. Defaults to the local models     directory for this tab.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.get_model","title":"<code>get_model(name)</code>","text":"<p>Return a model wrapper for the given name.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.get_model--parameters","title":"Parameters","text":"<p>name : str     Model name used to locate or create the model folder.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.get_model--returns","title":"Returns","text":"<p>SenoQuantSegmentationModel     Model wrapper instance.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.get_preloaded_model","title":"<code>get_preloaded_model(name)</code>","text":"<p>Return a preloaded model instance by name.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.list_model_names","title":"<code>list_model_names(task=None)</code>","text":"<p>List available model folders under the models root.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.list_model_names--parameters","title":"Parameters","text":"<p>task : str or None     Optional task filter such as \"nuclear\" or \"cytoplasmic\".</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.list_model_names--returns","title":"Returns","text":"<p>list[str]     Sorted model folder names.</p>"},{"location":"api/#senoquant.tabs.segmentation.backend.SegmentationBackend.preload_models","title":"<code>preload_models()</code>","text":"<p>Instantiate all discovered models once.</p>"},{"location":"api/#models-base-classes","title":"Models Base Classes","text":"<p>Model wrapper for segmentation resources.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel","title":"<code>SenoQuantSegmentationModel</code>","text":"<p>Handle per-model storage and metadata paths.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel--parameters","title":"Parameters","text":"<p>name : str     Model identifier used for folder creation. models_root : pathlib.Path or None     Optional root folder for model storage.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.class_path","title":"<code>class_path</code>  <code>property</code>","text":"<p>Return the path to the model class file.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.details_path","title":"<code>details_path</code>  <code>property</code>","text":"<p>Return the path to the details JSON file.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.__init__","title":"<code>__init__(name, models_root=None)</code>","text":"<p>Initialize the model wrapper and ensure its folder exists.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.cytoplasmic_input_modes","title":"<code>cytoplasmic_input_modes()</code>","text":"<p>Return supported input modes for cytoplasmic segmentation.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.cytoplasmic_input_modes--returns","title":"Returns","text":"<p>list[str]     Input modes, e.g., \"cytoplasmic\" or \"nuclear+cytoplasmic\".</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.cytoplasmic_nuclear_optional","title":"<code>cytoplasmic_nuclear_optional()</code>","text":"<p>Return whether the nuclear channel is optional for cytoplasmic mode.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.cytoplasmic_nuclear_optional--returns","title":"Returns","text":"<p>bool     True when the nuclear channel is optional.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.display_order","title":"<code>display_order()</code>","text":"<p>Return the optional display ordering for this model.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.display_order--returns","title":"Returns","text":"<p>float or None     Numeric ordering value if specified in details.json.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.list_settings","title":"<code>list_settings()</code>","text":"<p>Return the settings definitions for this model.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.list_settings--returns","title":"Returns","text":"<p>list[dict]     Settings definitions for building the UI.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.load_details","title":"<code>load_details()</code>","text":"<p>Load model metadata from the details file.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.load_details--returns","title":"Returns","text":"<p>dict     Parsed model metadata dictionary.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.run","title":"<code>run(**kwargs)</code>","text":"<p>Run the model with the provided inputs and settings.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.run--parameters","title":"Parameters","text":"<p>**kwargs     Model inputs and settings passed from the UI.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.run--returns","title":"Returns","text":"<p>dict or None     Result dictionary from the model, or None if not implemented.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.supports_task","title":"<code>supports_task(task)</code>","text":"<p>Return whether the model supports a given task.</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.supports_task--parameters","title":"Parameters","text":"<p>task : str     Task name, such as \"nuclear\" or \"cytoplasmic\".</p>"},{"location":"api/#senoquant.tabs.segmentation.models.base.SenoQuantSegmentationModel.supports_task--returns","title":"Returns","text":"<p>bool     True if the task is supported.</p>"},{"location":"api/#spot-detection","title":"Spot Detection","text":""},{"location":"api/#backend_1","title":"Backend","text":"<p>Backend logic for the Spots tab.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend","title":"<code>SpotsBackend</code>","text":"<p>Manage spot detectors and their storage locations.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend--parameters","title":"Parameters","text":"<p>models_root : pathlib.Path or None     Optional root folder for detector storage. Defaults to the local models     directory for this tab.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.compute_colocalization","title":"<code>compute_colocalization(data_a, data_b)</code>","text":"<p>Compute colocalization centroids from two label arrays.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.compute_colocalization--parameters","title":"Parameters","text":"<p>data_a : numpy.ndarray     First label layer data. data_b : numpy.ndarray     Second label layer data.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.compute_colocalization--returns","title":"Returns","text":"<p>dict     Dictionary containing the <code>points</code> array.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.get_detector","title":"<code>get_detector(name)</code>","text":"<p>Return a detector wrapper for the given name.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.get_detector--parameters","title":"Parameters","text":"<p>name : str     Detector name used to locate or create the detector folder.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.get_detector--returns","title":"Returns","text":"<p>SenoQuantSpotDetector     Detector instance.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.list_detector_names","title":"<code>list_detector_names()</code>","text":"<p>List available detector folders under the models root.</p>"},{"location":"api/#senoquant.tabs.spots.backend.SpotsBackend.list_detector_names--returns","title":"Returns","text":"<p>list[str]     Sorted detector folder names ordered by display_order, then by name.</p>"},{"location":"api/#detector-base-classes","title":"Detector Base Classes","text":"<p>Base class for spot detector implementations.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector","title":"<code>SenoQuantSpotDetector</code>","text":"<p>Handle per-detector storage and metadata paths.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector--parameters","title":"Parameters","text":"<p>name : str     Detector identifier used for folder creation. models_root : pathlib.Path or None     Optional root folder for detector storage.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.class_path","title":"<code>class_path</code>  <code>property</code>","text":"<p>Return the path to the detector class file.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.details_path","title":"<code>details_path</code>  <code>property</code>","text":"<p>Return the path to the details JSON file.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.__init__","title":"<code>__init__(name, models_root=None)</code>","text":"<p>Initialize the detector wrapper and ensure its folder exists.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.display_order","title":"<code>display_order()</code>","text":"<p>Return the optional display ordering for this detector.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.display_order--returns","title":"Returns","text":"<p>float or None     Numeric ordering value if specified in details.json.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.list_settings","title":"<code>list_settings()</code>","text":"<p>Return the settings definitions for this detector.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.list_settings--returns","title":"Returns","text":"<p>list[dict]     Settings definitions for building the UI.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.load_details","title":"<code>load_details()</code>","text":"<p>Load detector metadata from the details file.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.load_details--returns","title":"Returns","text":"<p>dict     Parsed detector metadata dictionary.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.run","title":"<code>run(**kwargs)</code>","text":"<p>Run the detector with the provided inputs and settings.</p>"},{"location":"api/#senoquant.tabs.spots.models.base.SenoQuantSpotDetector.run--parameters","title":"Parameters","text":"<p>**kwargs     Detector inputs and settings passed from the UI.</p>"},{"location":"api/#prediction","title":"Prediction","text":""},{"location":"api/#backend_2","title":"Backend","text":"<p>Backend logic for the Prediction tab.</p>"},{"location":"api/#senoquant.tabs.prediction.backend.PredictionBackend","title":"<code>PredictionBackend</code>","text":"<p>Manage prediction models and push outputs into a napari viewer.</p>"},{"location":"api/#senoquant.tabs.prediction.backend.PredictionBackend--parameters","title":"Parameters","text":"<p>models_root : pathlib.Path or None     Optional root folder for prediction models. Defaults to the local     <code>models</code> directory for this tab.</p>"},{"location":"api/#senoquant.tabs.prediction.backend.PredictionBackend.get_model","title":"<code>get_model(name)</code>","text":"<p>Return a prediction model wrapper for the given name.</p>"},{"location":"api/#senoquant.tabs.prediction.backend.PredictionBackend.list_model_names","title":"<code>list_model_names()</code>","text":"<p>List available prediction model folders under the models root.</p>"},{"location":"api/#senoquant.tabs.prediction.backend.PredictionBackend.push_layers_to_viewer","title":"<code>push_layers_to_viewer(viewer, model_name, result, source_layer=None)</code>","text":"<p>Add model-produced layers into the napari viewer.</p>"},{"location":"api/#senoquant.tabs.prediction.backend.PredictionBackend.run_model","title":"<code>run_model(model_name, *, viewer=None, settings=None, settings_widget=None)</code>","text":"<p>Run a prediction model and normalize its result payload.</p>"},{"location":"api/#model-base-classes","title":"Model Base Classes","text":"<p>Base class for prediction model implementations.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel","title":"<code>SenoQuantPredictionModel</code>","text":"<p>Handle per-model storage paths and runtime hooks for prediction models.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel--parameters","title":"Parameters","text":"<p>name : str     Model identifier used for folder creation. models_root : pathlib.Path or None     Optional root folder for model storage.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.class_path","title":"<code>class_path</code>  <code>property</code>","text":"<p>Return the path to the model class file.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.__init__","title":"<code>__init__(name, models_root=None)</code>","text":"<p>Initialize the model wrapper and ensure its folder exists.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.build_widget","title":"<code>build_widget(parent=None, viewer=None)</code>","text":"<p>Create and return a model-specific Qt widget.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.build_widget--parameters","title":"Parameters","text":"<p>parent : QWidget or None     Optional widget parent. viewer : object or None     Optional napari viewer passed by the prediction tab.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.build_widget--returns","title":"Returns","text":"<p>QWidget or None     Custom configuration widget for this model.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.collect_widget_settings","title":"<code>collect_widget_settings(settings_widget=None)</code>","text":"<p>Collect a serializable settings dictionary from a widget.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.collect_widget_settings--parameters","title":"Parameters","text":"<p>settings_widget : QWidget or None     Widget previously created by :meth:<code>build_widget</code>.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.collect_widget_settings--returns","title":"Returns","text":"<p>dict[str, object]     Settings payload passed into :meth:<code>run</code>.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.display_order","title":"<code>display_order()</code>","text":"<p>Return optional UI ordering for the model selector.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.display_order--returns","title":"Returns","text":"<p>float or None     Lower values are shown first. <code>None</code> means no explicit priority.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.run","title":"<code>run(**kwargs)</code>","text":"<p>Run the model with provided inputs and return layer payloads.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.run--parameters","title":"Parameters","text":"<p>**kwargs     Model-specific run payload, typically including <code>viewer</code> and     <code>settings</code>.</p>"},{"location":"api/#senoquant.tabs.prediction.models.base.SenoQuantPredictionModel.run--returns","title":"Returns","text":"<p>dict     Mapping with a <code>layers</code> entry compatible with napari-style     layer-data tuples.</p>"},{"location":"api/#quantification","title":"Quantification","text":""},{"location":"api/#backend_3","title":"Backend","text":"<p>Backend logic for the Quantification tab.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.FeatureExportResult","title":"<code>FeatureExportResult</code>  <code>dataclass</code>","text":"<p>Output metadata for a single feature export.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.FeatureExportResult--attributes","title":"Attributes","text":"<p>feature_id : str     Stable identifier for the exported feature instance. feature_type : str     Feature type name used for routing (e.g., <code>\"Markers\"</code>). feature_name : str     Display name provided by the user. temp_dir : Path     Temporary directory where the feature wrote its outputs. outputs : list of Path     Explicit file paths returned by the feature processor.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend","title":"<code>QuantificationBackend</code>","text":"<p>Backend orchestrator for quantification exports.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend--notes","title":"Notes","text":"<p>Feature export routines live with their feature implementations. The backend iterates through configured feature contexts, asks each feature handler to export into a temporary directory, and then routes those outputs into a final output structure.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the backend state.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend.__init__--attributes","title":"Attributes","text":"<p>metrics : list     Placeholder container for computed metrics.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend.process","title":"<code>process(features, output_path, output_name, export_format, cleanup=True)</code>","text":"<p>Run feature exports and route their outputs.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend.process--parameters","title":"Parameters","text":"<p>features : iterable of object     Feature UI contexts with <code>state</code> and <code>feature_handler</code>.     Each handler should implement <code>export(temp_dir, export_format)</code>. output_path : str     Base output folder path. output_name : str     Folder name used to group exported outputs. export_format : str     File format requested by the user (<code>\"csv\"</code> or <code>\"xlsx\"</code>). cleanup : bool, optional     Whether to delete temporary export folders after routing.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend.process--returns","title":"Returns","text":"<p>QuantificationResult     Output metadata for the completed run.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationBackend.process--notes","title":"Notes","text":"<p>If a feature export does not return explicit output paths, the backend will move all files found in the feature's temp directory. This allows feature implementations to either return specific files or simply write into the provided temporary directory.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationResult","title":"<code>QuantificationResult</code>  <code>dataclass</code>","text":"<p>Aggregated output information for a quantification run.</p>"},{"location":"api/#senoquant.tabs.quantification.backend.QuantificationResult--attributes","title":"Attributes","text":"<p>output_root : Path     Root output directory for the run. temp_root : Path     Temporary root directory used during processing. feature_outputs : list of FeatureExportResult     Per-feature export metadata for the run.</p>"},{"location":"api/#features-base-classes","title":"Features Base Classes","text":"<p>Feature UI base classes for quantification.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.FeatureConfig","title":"<code>FeatureConfig</code>  <code>dataclass</code>","text":"<p>Configuration for a single quantification feature.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.FeatureConfig--attributes","title":"Attributes","text":"<p>feature_id : str     Unique identifier for the feature instance. name : str     User-facing name for the feature. type_name : str     Feature type name (e.g., <code>\"Markers\"</code>). data : FeatureData     Feature-specific configuration payload.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.FeatureData","title":"<code>FeatureData</code>","text":"<p>Base class for feature-specific configuration data.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.FeatureData--notes","title":"Notes","text":"<p>Concrete feature data classes should inherit from this class so they can be stored on :class:<code>FeatureConfig</code>.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.RefreshingComboBox","title":"<code>RefreshingComboBox</code>","text":"<p>               Bases: <code>QComboBox</code></p> <p>Combo box that refreshes its items when opened.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.RefreshingComboBox.__init__","title":"<code>__init__(refresh_callback=None, parent=None)</code>","text":"<p>Create a combo box that refreshes before showing its popup.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.RefreshingComboBox.__init__--parameters","title":"Parameters","text":"<p>refresh_callback : callable or None     Callback invoked before showing the popup. parent : QWidget or None     Optional parent widget.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.RefreshingComboBox.showPopup","title":"<code>showPopup()</code>","text":"<p>Refresh items before showing the popup.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature","title":"<code>SenoQuantFeature</code>","text":"<p>Base class for quantification feature UI.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.__init__","title":"<code>__init__(tab, context)</code>","text":"<p>Initialize a feature with shared tab context.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.__init__--parameters","title":"Parameters","text":"<p>tab : QuantificationTab     Parent quantification tab instance. context : FeatureUIContext     Feature UI context with configuration state.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.build","title":"<code>build()</code>","text":"<p>Build the UI for this feature.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.export","title":"<code>export(temp_dir, export_format)</code>","text":"<p>Export feature outputs into a temporary directory.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.export--parameters","title":"Parameters","text":"<p>temp_dir : Path     Temporary directory where outputs should be written. export_format : str     File format requested by the user (<code>\"csv\"</code> or <code>\"xlsx\"</code>).</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.export--returns","title":"Returns","text":"<p>iterable of Path     Paths to files produced by the export routine.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.export--notes","title":"Notes","text":"<p>Implementations may either return explicit file paths or simply write outputs into <code>temp_dir</code> and return an empty iterable.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.on_features_changed","title":"<code>on_features_changed(configs)</code>","text":"<p>Handle updates when the feature list changes.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.on_features_changed--parameters","title":"Parameters","text":"<p>configs : list of FeatureUIContext     Current feature contexts.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.update_type_options","title":"<code>update_type_options(tab, configs)</code>  <code>classmethod</code>","text":"<p>Update type availability in feature selectors.</p>"},{"location":"api/#senoquant.tabs.quantification.features.base.SenoQuantFeature.update_type_options--parameters","title":"Parameters","text":"<p>tab : QuantificationTab     Parent quantification tab instance. configs : list of FeatureUIContext     Current feature contexts.</p>"},{"location":"api/#roi-configuration","title":"ROI Configuration","text":"<p>ROI selection UI helpers for quantification features.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROIConfig","title":"<code>ROIConfig</code>  <code>dataclass</code>","text":"<p>Configuration for a single ROI entry.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROIConfig--attributes","title":"Attributes","text":"<p>name : str     Display name for the ROI. layer : str     Shapes layer name used for the ROI. roi_type : str     Whether the ROI should be included or excluded.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROISection","title":"<code>ROISection</code>","text":"<p>Reusable ROI controls for marker and spots features.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROISection.__init__","title":"<code>__init__(tab, context, rois)</code>","text":"<p>Initialize the ROI helper for a feature.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROISection.__init__--parameters","title":"Parameters","text":"<p>tab : QuantificationTab     Parent quantification tab instance. context : FeatureUIContext     Feature UI context. rois : list of ROIConfig     Feature ROI configuration list.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROISection.build","title":"<code>build()</code>","text":"<p>Create the ROI controls and attach to the right column.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROISection.clear","title":"<code>clear()</code>","text":"<p>Remove all ROI rows and reset layout state.</p>"},{"location":"api/#senoquant.tabs.quantification.features.roi.ROISection.update_titles","title":"<code>update_titles()</code>","text":"<p>Refresh ROI section titles based on current feature order.</p>"},{"location":"api/#batch-processing","title":"Batch Processing","text":""},{"location":"api/#backend_4","title":"Backend","text":"<p>Batch processing backend.</p> <p>This module coordinates per-image batch processing for segmentation, spot detection, and quantification. It provides a single entry point (<code>BatchBackend.run_job</code>) that consumes a :class:<code>BatchJobConfig</code> and produces a :class:<code>BatchSummary</code> describing outputs and errors.</p> <p>The batch run flow is:</p> <ol> <li>Normalize input extensions and discover files.</li> <li>Resolve channel mapping for named channels.</li> <li>For each file (and each scene, if enabled):    a. Optionally run nuclear segmentation.    b. Optionally run cytoplasmic segmentation.    c. Optionally run spot detection for selected channels.    d. Optionally run quantification using a temporary viewer shim.</li> <li>Persist mask outputs and quantification results.</li> </ol>"},{"location":"api/#senoquant.tabs.batch.backend--notes","title":"Notes","text":"<p>This backend is intentionally UI-agnostic. UI widgets build a <code>BatchJobConfig</code> and pass it here for execution.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend","title":"<code>BatchBackend</code>","text":"<p>Backend for batch segmentation and spot detection workflows.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend.process_folder","title":"<code>process_folder(input_path, output_path, *, channel_map=None, nuclear_model=None, nuclear_channel=None, nuclear_settings=None, cyto_model=None, cyto_channel=None, cyto_nuclear_channel=None, cyto_settings=None, spot_detector=None, spot_channels=None, spot_settings=None, spot_min_size=0, spot_max_size=0, quantification_features=None, quantification_format='xlsx', quantification_tab=None, extensions=None, include_subfolders=False, overwrite=False, process_all_scenes=False, batch_job_payload=None, progress_callback=None)</code>","text":"<p>Run batch processing on a folder of images.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend.process_folder--parameters","title":"Parameters","text":"<p>input_path : str     Folder containing input images. output_path : str     Folder where outputs should be written. channel_map : iterable of BatchChannelConfig or dict, optional     Mapping from channel names to indices. nuclear_model : str or None, optional     Segmentation model name for nuclei. nuclear_channel : str or int or None, optional     Channel selection for nuclei. nuclear_settings : dict or None, optional     Model settings for nuclear segmentation. cyto_model : str or None, optional     Segmentation model name for cytoplasm. cyto_channel : str or int or None, optional     Channel selection for cytoplasm. cyto_nuclear_channel : str or int or None, optional     Optional nuclear input for cytoplasmic models. This may be a     channel selection or a generated nuclear label name. cyto_settings : dict or None, optional     Model settings for cytoplasmic segmentation. spot_detector : str or None, optional     Spot detection model name. spot_channels : iterable of str or int or None, optional     Channels used for spot detection. spot_settings : dict or None, optional     Detector settings. spot_min_size : int, optional     Minimum spot diameter in pixels (0 = no minimum). spot_max_size : int, optional     Maximum spot diameter in pixels (0 = no maximum). quantification_features : iterable of object or None, optional     Quantification feature contexts (UI-generated). quantification_format : str, optional     Output format for quantification (<code>\"csv\"</code> or <code>\"xlsx\"</code>). quantification_tab : object or None, optional     Quantification tab instance for viewer wiring. extensions : iterable of str or None, optional     File extensions to include. include_subfolders : bool, optional     Whether to recurse into subfolders. overwrite : bool, optional     Whether to overwrite existing output folders. process_all_scenes : bool, optional     Whether to process all scenes in multi-scene files. batch_job_payload : dict or None, optional     Optional pre-serialized <code>batch_job</code> payload to persist at the     output root as <code>senoquant_settings.json</code>. progress_callback : callable or None, optional     Optional callback invoked with (current, total, message) to     report progress during batch processing.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend.process_folder--returns","title":"Returns","text":"<p>BatchSummary     Summary of the batch run.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend.run_job","title":"<code>run_job(job)</code>","text":"<p>Run a batch job using a configuration object.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend.run_job--parameters","title":"Parameters","text":"<p>job : BatchJobConfig     Fully-populated batch configuration.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchBackend.run_job--returns","title":"Returns","text":"<p>BatchSummary     Summary of the batch run (counts + per-item metadata).</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchItemResult","title":"<code>BatchItemResult</code>  <code>dataclass</code>","text":"<p>Result metadata for a single processed image.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchItemResult--attributes","title":"Attributes","text":"<p>path : Path     Input file path. scene_id : str or None     Scene identifier for multi-scene files. outputs : dict of str to Path     Mapping of output labels to written files. errors : list of str     Collected error messages for this item.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchSummary","title":"<code>BatchSummary</code>  <code>dataclass</code>","text":"<p>Aggregated results for a batch run.</p>"},{"location":"api/#senoquant.tabs.batch.backend.BatchSummary--attributes","title":"Attributes","text":"<p>input_root : Path     Root input directory. output_root : Path     Root output directory. processed : int     Number of successfully processed items. skipped : int     Number of skipped items. failed : int     Number of failed items. results : list of BatchItemResult     Per-item metadata for the run.</p>"},{"location":"api/#configuration","title":"Configuration","text":"<p>Batch job configuration and serialization helpers.</p> <p>This module defines dataclasses used to capture batch settings from the UI. <code>BatchJobConfig.to_dict()</code> and <code>from_dict()</code> operate on the inner <code>batch_job</code> payload, while <code>save()</code> and <code>load()</code> persist that payload inside the shared <code>senoquant.settings</code> bundle envelope.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchChannelConfig","title":"<code>BatchChannelConfig</code>  <code>dataclass</code>","text":"<p>Channel mapping configuration.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchChannelConfig--attributes","title":"Attributes","text":"<p>name : str     User-facing channel name (used in UI and exports). index : int     Zero-based channel index in the input image.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchCytoplasmicConfig","title":"<code>BatchCytoplasmicConfig</code>  <code>dataclass</code>","text":"<p>Cytoplasmic segmentation configuration.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig","title":"<code>BatchJobConfig</code>  <code>dataclass</code>","text":"<p>Top-level batch configuration.</p> <p>This dataclass is the in-memory payload exchanged between the batch UI and backend. It also defines the inner <code>batch_job</code> payload embedded in saved settings bundles.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.from_dict","title":"<code>from_dict(payload)</code>  <code>classmethod</code>","text":"<p>Hydrate a job config from an inner <code>batch_job</code> payload.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.from_dict--parameters","title":"Parameters","text":"<p>payload : dict     JSON-compatible <code>batch_job</code> payload.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.from_dict--returns","title":"Returns","text":"<p>BatchJobConfig     Parsed configuration instance.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a configuration from disk.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.load--parameters","title":"Parameters","text":"<p>path : str     Source JSON settings file. Supports both bundle envelopes and     legacy plain batch payloads.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.load--returns","title":"Returns","text":"<p>BatchJobConfig     Loaded configuration instance.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.save","title":"<code>save(path)</code>","text":"<p>Persist the configuration to disk in bundle format.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.save--parameters","title":"Parameters","text":"<p>path : str     Destination file path for the JSON settings file. The file stores the     config inside a <code>senoquant.settings</code> bundle envelope.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize the inner batch payload to a JSON-friendly dictionary.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchJobConfig.to_dict--returns","title":"Returns","text":"<p>dict     JSON-compatible <code>batch_job</code> payload.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchQuantificationConfig","title":"<code>BatchQuantificationConfig</code>  <code>dataclass</code>","text":"<p>Quantification configuration.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchSegmentationConfig","title":"<code>BatchSegmentationConfig</code>  <code>dataclass</code>","text":"<p>Segmentation configuration for a single task.</p>"},{"location":"api/#senoquant.tabs.batch.config.BatchSpotsConfig","title":"<code>BatchSpotsConfig</code>  <code>dataclass</code>","text":"<p>Spot detection configuration.</p>"},{"location":"api/#io-utilities","title":"I/O Utilities","text":"<p>I/O helpers for batch processing.</p> <p>This module provides filesystem and image-loading utilities used by the batch backend. Functions are intentionally stateless and easy to mock in tests.</p>"},{"location":"api/#senoquant.tabs.batch.io.basename_for_path","title":"<code>basename_for_path(path)</code>","text":"<p>Return a filesystem-friendly base name for a file path.</p>"},{"location":"api/#senoquant.tabs.batch.io.basename_for_path--parameters","title":"Parameters","text":"<p>path : Path     Input file path.</p>"},{"location":"api/#senoquant.tabs.batch.io.basename_for_path--returns","title":"Returns","text":"<p>str     Base name with common microscopy extensions removed.</p>"},{"location":"api/#senoquant.tabs.batch.io.iter_input_files","title":"<code>iter_input_files(root, extensions, include_subfolders)</code>","text":"<p>Yield input files from a root folder.</p>"},{"location":"api/#senoquant.tabs.batch.io.iter_input_files--parameters","title":"Parameters","text":"<p>root : Path     Directory to scan. extensions : set of str or None     Allowed file extensions. None disables filtering. include_subfolders : bool     Whether to scan subfolders recursively.</p>"},{"location":"api/#senoquant.tabs.batch.io.iter_input_files--yields","title":"Yields","text":"<p>Path     File paths that match the extension criteria.</p>"},{"location":"api/#senoquant.tabs.batch.io.list_scenes","title":"<code>list_scenes(path)</code>","text":"<p>Return scene identifiers for a BioIO image path.</p>"},{"location":"api/#senoquant.tabs.batch.io.list_scenes--parameters","title":"Parameters","text":"<p>path : Path     Input file path.</p>"},{"location":"api/#senoquant.tabs.batch.io.list_scenes--returns","title":"Returns","text":"<p>list of str     Scene identifiers, or an empty list if unavailable.</p>"},{"location":"api/#senoquant.tabs.batch.io.load_channel_data","title":"<code>load_channel_data(path, channel_index, scene_id)</code>","text":"<p>Load a single-channel image array for the given path.</p>"},{"location":"api/#senoquant.tabs.batch.io.load_channel_data--parameters","title":"Parameters","text":"<p>path : Path     Input file path. channel_index : int     Channel index to extract. scene_id : str or None     Optional scene identifier.</p>"},{"location":"api/#senoquant.tabs.batch.io.load_channel_data--returns","title":"Returns","text":"<p>tuple of (numpy.ndarray or None, dict)     The extracted image data and metadata.</p>"},{"location":"api/#senoquant.tabs.batch.io.normalize_extensions","title":"<code>normalize_extensions(extensions)</code>","text":"<p>Normalize extension list to lowercase with leading dots.</p>"},{"location":"api/#senoquant.tabs.batch.io.normalize_extensions--parameters","title":"Parameters","text":"<p>extensions : iterable of str or None     Raw extension strings (with or without dots).</p>"},{"location":"api/#senoquant.tabs.batch.io.normalize_extensions--returns","title":"Returns","text":"<p>set of str or None     Normalized extensions or None when no filtering is requested.</p>"},{"location":"api/#senoquant.tabs.batch.io.resolve_channel_index","title":"<code>resolve_channel_index(choice, channel_map)</code>","text":"<p>Resolve a channel selection into a numeric index.</p>"},{"location":"api/#senoquant.tabs.batch.io.resolve_channel_index--parameters","title":"Parameters","text":"<p>choice : str or int or None     Channel selection from the UI (name or index). channel_map : list of BatchChannelConfig     Mapping from names to indices.</p>"},{"location":"api/#senoquant.tabs.batch.io.resolve_channel_index--returns","title":"Returns","text":"<p>int     Resolved channel index.</p>"},{"location":"api/#senoquant.tabs.batch.io.resolve_channel_index--raises","title":"Raises","text":"<p>ValueError     If the selection is missing or unknown.</p>"},{"location":"api/#senoquant.tabs.batch.io.safe_scene_dir","title":"<code>safe_scene_dir(scene_id)</code>","text":"<p>Return a sanitized scene identifier for folder naming.</p>"},{"location":"api/#senoquant.tabs.batch.io.safe_scene_dir--parameters","title":"Parameters","text":"<p>scene_id : str     Scene identifier from BioIO.</p>"},{"location":"api/#senoquant.tabs.batch.io.safe_scene_dir--returns","title":"Returns","text":"<p>str     Filesystem-safe scene folder name.</p>"},{"location":"api/#senoquant.tabs.batch.io.sanitize_label","title":"<code>sanitize_label(name)</code>","text":"<p>Sanitize a label name for filesystem use.</p>"},{"location":"api/#senoquant.tabs.batch.io.spot_label_name","title":"<code>spot_label_name(choice, channel_map)</code>","text":"<p>Build the output label name for a spot channel.</p>"},{"location":"api/#senoquant.tabs.batch.io.spot_label_name--parameters","title":"Parameters","text":"<p>choice : str or int     Channel selection. channel_map : list of BatchChannelConfig     Channel mapping list for name lookup.</p>"},{"location":"api/#senoquant.tabs.batch.io.spot_label_name--returns","title":"Returns","text":"<p>str     Standardized spot label name.</p>"},{"location":"api/#senoquant.tabs.batch.io.write_array","title":"<code>write_array(output_dir, name, data)</code>","text":"<p>Write an array to disk as <code>.npy</code>.</p>"},{"location":"api/#senoquant.tabs.batch.io.write_array--parameters","title":"Parameters","text":"<p>output_dir : Path     Destination folder. name : str     Base name for the output file. data : numpy.ndarray     Array data to serialize. Returns</p> <p>Path     Path to the written file.</p>"},{"location":"api/#viewer-shim","title":"Viewer Shim","text":"<p>Lightweight layer shims used for batch processing.</p> <p>These classes emulate the minimal attributes used by feature exporters and quantification routines, without requiring a live napari viewer.</p>"},{"location":"api/#senoquant.tabs.batch.layers.BatchViewer","title":"<code>BatchViewer</code>","text":"<p>Minimal viewer shim exposing layers for export routines.</p>"},{"location":"api/#senoquant.tabs.batch.layers.BatchViewer--parameters","title":"Parameters","text":"<p>layers : iterable of object or None, optional     Initial layer collection.</p>"},{"location":"api/#senoquant.tabs.batch.layers.BatchViewer.__init__","title":"<code>__init__(layers=None)</code>","text":"<p>Initialize the viewer shim.</p>"},{"location":"api/#senoquant.tabs.batch.layers.BatchViewer.set_layers","title":"<code>set_layers(layers)</code>","text":"<p>Replace the current layer collection.</p>"},{"location":"api/#senoquant.tabs.batch.layers.BatchViewer.set_layers--parameters","title":"Parameters","text":"<p>layers : iterable of object     New layer collection.</p>"},{"location":"api/#senoquant.tabs.batch.layers.Image","title":"<code>Image</code>","text":"<p>Lightweight image layer placeholder.</p>"},{"location":"api/#senoquant.tabs.batch.layers.Image--parameters","title":"Parameters","text":"<p>data : numpy.ndarray or None     Image data array. name : str     Layer name. metadata : dict or None, optional     Metadata dictionary (e.g., pixel sizes). rgb : bool, optional     Whether the layer should be treated as RGB.</p>"},{"location":"api/#senoquant.tabs.batch.layers.Labels","title":"<code>Labels</code>","text":"<p>Lightweight labels layer placeholder.</p>"},{"location":"api/#senoquant.tabs.batch.layers.Labels--parameters","title":"Parameters","text":"<p>data : numpy.ndarray or None     Label image data. name : str     Layer name. metadata : dict or None, optional     Metadata dictionary (e.g., pixel sizes).</p>"},{"location":"api/#settings","title":"Settings","text":"<p>Backend helpers for shared settings persistence in the Settings tab.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend","title":"<code>SettingsBackend</code>","text":"<p>               Bases: <code>QObject</code></p> <p>Read and write unified settings bundle payloads.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the backend.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.build_bundle","title":"<code>build_bundle(*, segmentation=None, spots=None, batch_job=None)</code>","text":"<p>Build a normalized settings bundle payload for UI settings.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.build_bundle--parameters","title":"Parameters","text":"<p>segmentation : dict or None, optional     Segmentation tab settings state payload. spots : dict or None, optional     Spots tab settings state payload. batch_job : dict or None, optional     Batch tab settings payload, when available.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.build_bundle--returns","title":"Returns","text":"<p>dict of str to Any     Canonical <code>senoquant.settings</code> bundle payload.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.default_settings_filename","title":"<code>default_settings_filename()</code>  <code>classmethod</code>","text":"<p>Return the default JSON filename used for settings exports.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.load_bundle","title":"<code>load_bundle(path)</code>","text":"<p>Load and normalize a settings bundle from disk.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.parse_bundle","title":"<code>parse_bundle(payload)</code>  <code>staticmethod</code>","text":"<p>Parse raw JSON payload into a normalized settings bundle.</p>"},{"location":"api/#senoquant.tabs.settings.backend.SettingsBackend.save_bundle","title":"<code>save_bundle(path, payload)</code>","text":"<p>Write a settings bundle payload to disk.</p>"},{"location":"developer/adding-tabs/","title":"Adding tabs","text":"<p>This guide describes how to add a new tab to the main SenoQuant widget.</p>"},{"location":"developer/adding-tabs/#where-tabs-are-wired","title":"Where tabs are wired","text":"<p>Three files are the core wiring points:</p> <ul> <li><code>src/senoquant/tabs/&lt;tab_name&gt;/frontend.py</code>: tab UI (<code>QWidget</code>).</li> <li><code>src/senoquant/tabs/&lt;tab_name&gt;/backend.py</code>: processing/discovery logic.</li> <li><code>src/senoquant/_widget.py</code>: adds the tab to <code>SenoQuantWidget</code>.</li> </ul> <p>You also export tab classes from <code>src/senoquant/tabs/__init__.py</code>.</p> <p>Concrete examples in the current repo:</p> <ul> <li><code>src/senoquant/tabs/prediction/</code> for a tab that hosts dynamically loaded   model-defined widgets.</li> <li><code>src/senoquant/tabs/segmentation/</code> for a tab with larger split frontend   mixins.</li> </ul>"},{"location":"developer/adding-tabs/#step-by-step","title":"Step-by-step","text":""},{"location":"developer/adding-tabs/#1-create-the-tab-package","title":"1) Create the tab package","text":"<p>Create a folder:</p> <p><code>src/senoquant/tabs/&lt;tab_name&gt;/</code></p> <p>Add at least:</p> <ul> <li><code>frontend.py</code>.</li> <li><code>backend.py</code>.</li> </ul> <p>Minimal scaffold:</p> <pre><code># src/senoquant/tabs/my_tab/backend.py\nclass MyTabBackend:\n    def __init__(self) -&gt; None:\n        self.state = {}\n</code></pre> <pre><code># src/senoquant/tabs/my_tab/frontend.py\nfrom qtpy.QtWidgets import QVBoxLayout, QWidget\nfrom .backend import MyTabBackend\n\n\nclass MyTab(QWidget):\n    def __init__(self, backend: MyTabBackend | None = None, napari_viewer=None) -&gt; None:\n        super().__init__()\n        self._backend = backend or MyTabBackend()\n        self._viewer = napari_viewer\n        layout = QVBoxLayout()\n        layout.addStretch(1)\n        self.setLayout(layout)\n</code></pre>"},{"location":"developer/adding-tabs/#2-export-the-tab-class","title":"2) Export the tab class","text":"<p>Update <code>src/senoquant/tabs/__init__.py</code>:</p> <ul> <li>Import your tab class.</li> <li>Add it to <code>__all__</code>.</li> </ul>"},{"location":"developer/adding-tabs/#3-add-the-tab-to-the-main-widget","title":"3) Add the tab to the main widget","text":"<p>Update <code>src/senoquant/_widget.py</code>:</p> <ul> <li>Import your tab class from <code>.tabs</code>.</li> <li>Add <code>tabs.addTab(MyTab(...), \"My tab label\")</code> in <code>SenoQuantWidget.__init__</code>.</li> </ul> <p>If the tab participates in shared settings persistence, wire it in <code>SenoQuantWidget</code> and pass tab references into <code>SettingsTab</code> so it can export/import that tab's state (same pattern used for Segmentation, Spots, and Batch tabs). Prediction is currently not part of Settings-tab save/load.</p>"},{"location":"developer/adding-tabs/#4-add-tests","title":"4) Add tests","text":"<p>At minimum:</p> <ul> <li>Add a smoke test in <code>tests/senoquant/tabs/test_ui_smoke.py</code> that   instantiates your tab.</li> <li>If your tab has backend behavior, add backend unit tests in   <code>tests/senoquant/tabs/&lt;tab_name&gt;/</code>.</li> </ul>"},{"location":"developer/adding-tabs/#5-update-docs-navigation","title":"5) Update docs navigation","text":"<p>Add the tab docs page to <code>mkdocs.yml</code> in the correct section (user or developer).</p>"},{"location":"developer/adding-tabs/#do-you-need-to-edit-napariyaml","title":"Do you need to edit <code>napari.yaml</code>?","text":"<p>Usually no.</p> <p>Current plugin wiring exposes a single widget command:</p> <ul> <li><code>senoquant.make_widget -&gt; senoquant._widget:SenoQuantWidget</code>.</li> </ul> <p>If your new tab is part of <code>SenoQuantWidget</code>, no new napari command is needed. Only update <code>napari.yaml</code> if you want to expose a separate plugin widget.</p>"},{"location":"developer/adding-tabs/#integration-checklist","title":"Integration checklist","text":"<ul> <li>New tab class exists and is importable.</li> <li>Exported from <code>src/senoquant/tabs/__init__.py</code>.</li> <li>Added to <code>SenoQuantWidget</code> in <code>src/senoquant/_widget.py</code>.</li> <li>Smoke tests added/updated.</li> <li>Docs and <code>mkdocs.yml</code> updated.</li> </ul>"},{"location":"developer/architecture/","title":"Architecture","text":"<p>This repo is a napari plugin organized around a Qt widget and a set of tab modules.</p>"},{"location":"developer/architecture/#entry-points","title":"Entry points","text":"<ul> <li><code>src/senoquant/napari.yaml</code> declares the napari widget and reader.</li> <li><code>src/senoquant/_widget.py</code> defines <code>SenoQuantWidget</code> and registers the   tabbed UI.</li> <li><code>src/senoquant/_reader.py</code> exposes the reader entrypoint.</li> </ul>"},{"location":"developer/architecture/#ui-structure","title":"UI structure","text":"<p>The main widget (<code>SenoQuantWidget</code>) composes seven tabs:</p> <ul> <li>Segmentation (<code>src/senoquant/tabs/segmentation</code>).</li> <li>Spots (<code>src/senoquant/tabs/spots</code>).</li> <li>Prediction (<code>src/senoquant/tabs/prediction</code>).</li> <li>Quantification (<code>src/senoquant/tabs/quantification</code>).</li> <li>Visualization (<code>src/senoquant/tabs/visualization</code>).</li> <li>Batch (<code>src/senoquant/tabs/batch</code>).</li> <li>Settings (<code>src/senoquant/tabs/settings</code>).</li> </ul> <p>Each tab follows a frontend/backend split:</p> <ul> <li><code>frontend.py</code> builds the Qt widgets and handles UI events.</li> <li><code>backend.py</code> performs the model discovery or processing logic.</li> <li>Segmentation additionally uses <code>segmentation/_frontend/</code> mixins to keep UI   code split across smaller modules.</li> </ul> <p>Prediction-specific note:</p> <ul> <li>The tab-level UI is fixed (<code>Select model</code>, <code>Model interface</code>, <code>Run</code>), and   each prediction model contributes its own Qt widget through   <code>SenoQuantPredictionModel.build_widget(...)</code>.</li> </ul>"},{"location":"developer/architecture/#reader-pipeline","title":"Reader pipeline","text":"<p>The reader implementation lives in <code>src/senoquant/reader/core.py</code> and relies on BioIO to open files. The reader:</p> <ul> <li>Validates the file via <code>BioImage.determine_plugin</code>.</li> <li>Iterates scenes and channels to create napari layers.</li> <li>Applies a fixed colormap cycle for channel display.</li> </ul>"},{"location":"developer/architecture/#batch-pipeline","title":"Batch pipeline","text":"<p>Batch processing is orchestrated by <code>BatchBackend</code> in <code>src/senoquant/tabs/batch/backend.py</code>. The flow is:</p> <ol> <li>Enumerate input files and resolve channel indices.</li> <li>Run segmentation (nuclear/cytoplasmic) as configured.</li> <li>Run spot detection per selected channels, then apply optional    diameter-based spot filtering.</li> <li>Run quantification using a lightweight viewer shim.</li> <li>Write masks and quantification outputs to disk.</li> <li>Persist <code>senoquant_settings.json</code> in the batch output root with the    effective <code>batch_job</code> configuration.</li> </ol>"},{"location":"developer/architecture/#prediction-pipeline","title":"Prediction pipeline","text":"<p>Prediction runs are orchestrated by <code>PredictionTab</code> + <code>PredictionBackend</code>:</p> <ol> <li>Discover model folders under <code>src/senoquant/tabs/prediction/models/</code>.</li> <li>Load the selected model class from <code>&lt;model_name&gt;/model.py</code>.</li> <li>Build model-defined UI in the <code>Model interface</code> box.</li> <li>Collect model widget settings and run model code in a background thread.</li> <li>Normalize model output into napari layer specs and add layers to the    viewer.</li> <li>Append run metadata (<code>task=\"prediction\"</code>, runner name/type, settings).</li> </ol>"},{"location":"developer/architecture/#settings-storage","title":"Settings storage","text":"<p>The Settings tab uses <code>SettingsBackend</code> to read/write unified <code>senoquant.settings</code> JSON bundles. These bundles can include:</p> <ul> <li><code>tab_settings</code> payloads for tab-level settings snapshots.</li> <li><code>batch_job</code> payloads compatible with batch config serialization.</li> <li><code>feature_settings</code> and <code>segmentation_runs</code> payloads produced by   quantification exports.</li> </ul>"},{"location":"developer/architecture/#cross-tab-settings-orchestration","title":"Cross-tab settings orchestration","text":"<p><code>SenoQuantWidget</code> instantiates all tab widgets. Settings currently receives Segmentation, Spots, and Batch tab references and uses them to:</p> <ul> <li>Export segmentation and spots configuration into <code>tab_settings</code>.</li> <li>Export batch state into <code>batch_job</code>.</li> <li>Restore those states when loading a bundle.</li> </ul> <p>Prediction, Quantification, and Visualization settings are currently not restored by the Settings tab.</p>"},{"location":"developer/batch-profiles/","title":"Batch settings bundles","text":"<p>This page replaces the old \u201cBatch profiles\u201d workflow.</p> <p>Batch settings are now serialized in the unified <code>senoquant.settings</code> bundle format, shared across tabs and exports.</p>"},{"location":"developer/batch-profiles/#current-behavior","title":"Current behavior","text":"<ul> <li>The Batch tab UI no longer provides Load/Save profile buttons.</li> <li>Settings are saved/loaded through the Settings tab.</li> <li>Batch runs automatically write a <code>senoquant_settings.json</code> file into the   batch output root.</li> </ul>"},{"location":"developer/batch-profiles/#bundle-envelope","title":"Bundle envelope","text":"<p>All persisted settings use a top-level envelope:</p> <pre><code>{\n  \"schema\": \"senoquant.settings\",\n  \"version\": 1,\n  \"batch_job\": {},\n  \"tab_settings\": {},\n  \"feature_settings\": {},\n  \"segmentation_runs\": []\n}\n</code></pre> <p>For batch settings, <code>batch_job</code> is the key payload and other sections may be empty.</p> <p>Canonical JSON Schema for this envelope is stored at <code>src/senoquant/utils/settings_bundle.schema.json</code>.</p>"},{"location":"developer/batch-profiles/#batch_job-payload-schema","title":"<code>batch_job</code> payload schema","text":"<p><code>batch_job</code> maps directly to <code>BatchJobConfig</code> in <code>src/senoquant/tabs/batch/config.py</code>.</p> <pre><code>{\n  \"input_path\": \"/path/to/images\",\n  \"output_path\": \"/path/to/output\",\n  \"extensions\": [\".tif\", \".ome.tif\"],\n  \"include_subfolders\": false,\n  \"process_all_scenes\": false,\n  \"overwrite\": false,\n  \"channel_map\": [\n    {\"name\": \"DAPI\", \"index\": 0},\n    {\"name\": \"FITC\", \"index\": 1}\n  ],\n  \"nuclear\": {\n    \"enabled\": true,\n    \"model\": \"default_2d\",\n    \"channel\": \"DAPI\",\n    \"settings\": {}\n  },\n  \"cytoplasmic\": {\n    \"enabled\": false,\n    \"model\": \"cpsam\",\n    \"channel\": \"FITC\",\n    \"nuclear_channel\": \"DAPI\",\n    \"settings\": {}\n  },\n  \"spots\": {\n    \"enabled\": false,\n    \"detector\": \"ufish\",\n    \"channels\": [\"FITC\"],\n    \"settings\": {},\n    \"min_size\": 0,\n    \"max_size\": 0\n  },\n  \"quantification\": {\n    \"enabled\": true,\n    \"format\": \"xlsx\",\n    \"features\": []\n  }\n}\n</code></pre> <p><code>spots.min_size</code> and <code>spots.max_size</code> are legacy field names kept for compatibility, but are interpreted as diameter thresholds in pixels when filtering labels (2D effective area, 3D effective volume).</p>"},{"location":"developer/batch-profiles/#where-persistence-happens","title":"Where persistence happens","text":""},{"location":"developer/batch-profiles/#settings-tab-saveload","title":"Settings tab save/load","text":"<ul> <li>Save builds a bundle with:</li> <li><code>tab_settings</code> section for segmentation/spots tab state.</li> <li><code>batch_job</code> section from current Batch tab config.</li> <li>Load applies:</li> <li>Segmentation and spots UI state from <code>tab_settings</code>.</li> <li>Batch tab state from <code>batch_job</code> when present.</li> </ul>"},{"location":"developer/batch-profiles/#batch-run-output","title":"Batch run output","text":"<p><code>BatchBackend.process_folder()</code> writes <code>output_root/senoquant_settings.json</code> before per-file processing begins. This captures the effective run config with outputs.</p>"},{"location":"developer/batch-profiles/#programmatic-api","title":"Programmatic API","text":"<p><code>BatchJobConfig.save()</code> and <code>BatchJobConfig.load()</code> still exist for scripted use and compatibility; they read/write the same bundle envelope.</p>"},{"location":"developer/batch-profiles/#legacy-compatibility","title":"Legacy compatibility","text":"<p><code>parse_settings_bundle()</code> accepts both:</p> <ul> <li>Legacy plain batch payloads (without the envelope), wrapped into <code>batch_job</code>.</li> <li>Legacy envelope payloads that stored settings under <code>feature</code>; these are   mapped to <code>tab_settings</code> when <code>feature.kind == \"tab_settings\"</code>, otherwise   to <code>feature_settings</code>.</li> </ul> <p>This preserves backward compatibility for older JSON files.</p>"},{"location":"developer/batch-profiles/#developer-checklist-for-batch-config-changes","title":"Developer checklist for batch config changes","text":"<p>When adding fields to batch configuration:</p> <ol> <li>Update <code>BatchJobConfig</code> dataclasses in <code>src/senoquant/tabs/batch/config.py</code>.</li> <li>Update serialization in <code>to_dict()</code> / <code>from_dict()</code>.</li> <li>Update fallback derivation in    <code>src/senoquant/tabs/batch/backend.py::_derive_batch_job_payload</code>.</li> <li>Update settings-tab integration expectations if needed.</li> <li>Add/adjust tests:</li> <li><code>tests/senoquant/tabs/batch/test_config.py</code></li> <li><code>tests/senoquant/tabs/batch/test_batch_backend.py</code></li> <li><code>tests/senoquant/tabs/settings/test_frontend.py</code></li> </ol>"},{"location":"developer/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to SenoQuant. This guide helps you set up a development environment and follow the project workflow.</p>"},{"location":"developer/contributing/#development-setup","title":"Development setup","text":""},{"location":"developer/contributing/#environment-creation","title":"Environment creation","text":"<pre><code>conda create -n senoquant-dev python=3.11\nconda activate senoquant-dev\npip install uv\nuv pip install \"napari[all]\"\nuv pip install -e .\n</code></pre>"},{"location":"developer/contributing/#verify-installation","title":"Verify installation","text":"<p>Launch napari and open the plugin from the <code>Plugins</code> menu.</p> <pre><code>napari\n</code></pre> <p>Select <code>Plugins</code> -&gt; <code>SenoQuant</code> to verify the plugin loads correctly.</p>"},{"location":"developer/contributing/#testing","title":"Testing","text":""},{"location":"developer/contributing/#running-tests","title":"Running tests","text":"<p>The project uses <code>pytest</code> with an 80% coverage requirement.</p> <pre><code>conda activate senoquant-dev\npytest\n</code></pre>"},{"location":"developer/contributing/#test-configuration","title":"Test configuration","text":"<ul> <li>Config file: <code>pytest.ini</code> specifies coverage thresholds and test discovery.</li> <li>Fixtures: <code>tests/conftest.py</code> provides stubs for headless GUI dependencies (DummySignal and mock napari layers).</li> <li>Coverage: Tests require &gt;=80% line coverage to pass.</li> </ul>"},{"location":"developer/contributing/#writing-tests","title":"Writing tests","text":"<p>When adding new functionality:</p> <ol> <li>Create test modules in the corresponding <code>tests/</code> subdirectory.</li> <li>Use fixtures from <code>conftest.py</code> for napari layer mocks.</li> <li>Leverage <code>tmp_path</code> for isolated file operations.</li> <li>Mock external dependencies (BioIO and Qt signals) where appropriate.</li> </ol> <p>Example test structure:</p> <pre><code>def test_new_feature(tmp_path):\n    # Arrange.\n    test_file = tmp_path / \"test.tif\"\n    test_file.write_bytes(b\"fake data\")\n\n    # Act.\n    result = my_function(test_file)\n\n    # Assert.\n    assert result is not None\n</code></pre>"},{"location":"developer/contributing/#headless-testing","title":"Headless testing","text":"<p>Tests run without a display server.</p> <ul> <li>Qt dependencies are stubbed in <code>conftest.py</code>.</li> <li>Avoid importing GUI modules at top level in test files.</li> <li>Use <code>pytest-qt</code> for Qt-specific testing when needed.</li> </ul>"},{"location":"developer/contributing/#documentation","title":"Documentation","text":""},{"location":"developer/contributing/#building-documentation-locally","title":"Building documentation locally","text":"<p>Install documentation dependencies.</p> <pre><code>pip install mkdocs mkdocs-material mkdocstrings[python]\n</code></pre> <p>Serve documentation locally for live preview.</p> <pre><code>mkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000</code> to view the docs.</p> <p>Build the static site.</p> <pre><code>mkdocs build\n</code></pre>"},{"location":"developer/contributing/#documentation-structure","title":"Documentation structure","text":"<ul> <li>User guide (<code>docs/user/</code>): End-user documentation for each plugin tab.</li> <li>Developer guide (<code>docs/developer/</code>): Architecture, models, features, and contribution details.</li> <li>API reference (<code>docs/api/</code>): Auto-generated via mkdocstrings (do not edit manually).</li> </ul>"},{"location":"developer/contributing/#writing-documentation","title":"Writing documentation","text":"<ul> <li>Use Markdown with Material for MkDocs extensions.</li> <li>Include code examples with proper syntax highlighting.</li> <li>Add screenshots to <code>docs/assets/</code> for UI documentation.</li> <li>Reference specific line numbers when linking to code, for example: <code>[file.py](file.py#L10)</code>.</li> </ul>"},{"location":"developer/contributing/#code-conventions","title":"Code conventions","text":""},{"location":"developer/contributing/#style-guidelines","title":"Style guidelines","text":"<ul> <li>Type hints: Use modern Python 3.11+ type annotations.</li> <li>Docstrings: Use NumPy style for public APIs.</li> <li>Imports: Use absolute imports from <code>senoquant</code>.</li> <li>File paths: Use <code>pathlib.Path</code> instead of string paths.</li> </ul>"},{"location":"developer/contributing/#architecture-patterns","title":"Architecture patterns","text":"<ul> <li>Frontend/backend split: Each tab has <code>frontend.py</code> (Qt UI) and <code>backend.py</code> (pure logic).</li> <li>Settings schema: For segmentation/spots, keep <code>details.json</code> compatible with <code>src/senoquant/utils/model_details.schema.json</code>.</li> <li>Model discovery:</li> <li>Segmentation/spots use <code>models/&lt;name&gt;/details.json</code> + <code>model.py</code>.</li> <li>Prediction uses <code>models/&lt;name&gt;/model.py</code> (no <code>details.json</code> required).</li> <li>Dataclasses: Use <code>@dataclass(slots=True)</code> for config objects.</li> </ul>"},{"location":"developer/contributing/#naming-conventions","title":"Naming conventions","text":"<ul> <li>Segmentation outputs: <code>&lt;image&gt;_&lt;model&gt;_nuc_labels</code> or <code>&lt;image&gt;_&lt;model&gt;_cyto_labels</code>.</li> <li>Spot outputs: <code>&lt;image&gt;_&lt;detector&gt;_spot_labels</code>.</li> <li>Private methods: Prefix with <code>_</code> (for example, <code>_compute_internal()</code>).</li> <li>Signals: Qt signals use past tense (for example, <code>segmentation_completed</code> and <code>error_occurred</code>).</li> </ul>"},{"location":"developer/contributing/#dependencies","title":"Dependencies","text":""},{"location":"developer/contributing/#core-dependencies","title":"Core dependencies","text":"<ul> <li>napari: Not pinned in <code>pyproject.toml</code>; install separately.</li> <li>Qt: Via QtPy (supports PyQt5, PyQt6, PySide2, and PySide6).</li> <li>BioIO: Format-agnostic image reader with 50+ plugins.</li> <li>ONNX Runtime: For StarDist model inference.</li> </ul>"},{"location":"developer/contributing/#optional-dependencies","title":"Optional dependencies","text":"<p>Defined in <code>pyproject.toml</code>:</p> <ul> <li><code>.[all]</code>: Full stack including napari and optional dependencies.</li> </ul>"},{"location":"developer/contributing/#extending-senoquant","title":"Extending SenoQuant","text":""},{"location":"developer/contributing/#segmentation-model","title":"Segmentation model","text":"<ol> <li>Create folder: <code>src/senoquant/tabs/segmentation/models/my_model/</code>.</li> <li>Add metadata: <code>details.json</code> with model info, tasks, and settings.</li> <li>Implement logic: <code>model.py</code> subclassing <code>SenoQuantSegmentationModel</code>.</li> <li>Test: Verify the model appears in the Segmentation tab dropdown.</li> </ol> <p>See Models &amp; Detectors for the detailed guide.</p>"},{"location":"developer/contributing/#spot-detector","title":"Spot detector","text":"<p>Use the same pattern as segmentation models under <code>src/senoquant/tabs/spots/models/</code>.</p>"},{"location":"developer/contributing/#prediction-model","title":"Prediction model","text":"<ol> <li>Create folder: <code>src/senoquant/tabs/prediction/models/my_model/</code>.</li> <li>Implement logic: <code>model.py</code> subclassing <code>SenoQuantPredictionModel</code>.</li> <li>Provide UI hooks: implement <code>build_widget()</code> + <code>collect_widget_settings()</code>.</li> <li>Return layers: implement <code>run()</code> to return napari-compatible layer specs.</li> </ol> <p>See Prediction models for the detailed guide.</p>"},{"location":"developer/contributing/#quantification-feature","title":"Quantification feature","text":"<ol> <li>Create module: <code>src/senoquant/tabs/quantification/features/my_feature/</code>.</li> <li>Define data class: Subclass <code>FeatureData</code> for configuration state.</li> <li>Implement feature: Subclass <code>SenoQuantFeature</code> with <code>build()</code> and <code>export()</code> methods.</li> <li>Register: Add to <code>FEATURE_DATA_FACTORY</code> in <code>features/__init__.py</code>.</li> <li>Batch settings bundles: Update batch feature serialize/deserialize cases in <code>src/senoquant/tabs/batch/config.py</code>.</li> </ol> <p>See Quantification features for the detailed guide.</p>"},{"location":"developer/contributing/#visualization-plot","title":"Visualization plot","text":"<ol> <li>Create module: <code>src/senoquant/tabs/visualization/plots/my_plot.py</code>.</li> <li>Define plot class: Subclass <code>SenoQuantPlot</code> with <code>plot_type</code> and <code>order</code>.</li> <li>Implement output: Write files in <code>plot(temp_dir, input_path, export_format, ...)</code>.</li> <li>Register typed data: Add custom <code>PlotData</code> class to <code>PLOT_DATA_FACTORY</code> when needed.</li> <li>Test: Add handler and backend tests under <code>tests/senoquant/tabs/visualization/</code>.</li> </ol> <p>See Visualization tab for implementation details.</p>"},{"location":"developer/contributing/#new-tab","title":"New tab","text":"<p>Create a new tab package under <code>src/senoquant/tabs/</code>, export it from <code>src/senoquant/tabs/__init__.py</code>, and wire it into <code>src/senoquant/_widget.py</code>.</p> <p>See Adding tabs for the full wiring checklist.</p>"},{"location":"developer/contributing/#submitting-changes","title":"Submitting changes","text":""},{"location":"developer/contributing/#pull-request-checklist","title":"Pull request checklist","text":"<ul> <li>[ ] Tests pass locally (<code>pytest</code>).</li> <li>[ ] Code follows style conventions.</li> <li>[ ] New features have test coverage.</li> <li>[ ] Documentation is updated (user docs, docstrings, and developer guides).</li> <li>[ ] No breaking changes to the batch config format (maintain backward compatibility).</li> </ul>"},{"location":"developer/contributing/#commit-messages","title":"Commit messages","text":"<p>Use descriptive commit messages.</p> <pre><code>Improve U-FISH spot detector threshold behavior\n\n- Adjust threshold handling for edge cases.\n- Update detector settings help text.\n- Add regression tests for low-signal images.\n</code></pre>"},{"location":"developer/contributing/#common-pitfalls","title":"Common pitfalls","text":"<ol> <li>Protobuf version conflicts: Reinstall protobuf after TensorFlow when doing ONNX conversion.</li> <li>Headless testing: <code>conftest.py</code> stubs handle missing Qt/napari; avoid top-level GUI imports in test files.</li> <li>Model not discovered:</li> <li>Segmentation/Spots: check folder naming and confirm <code>details.json</code> exists.</li> <li>Prediction: check folder naming and confirm <code>model.py</code> defines a <code>SenoQuantPredictionModel</code> subclass.</li> <li>Batch quantification failures: Verify the <code>BatchViewer</code> shim has correct layer names.</li> </ol>"},{"location":"developer/contributing/#getting-help","title":"Getting help","text":"<ul> <li>GitHub issues: Report bugs or request features.</li> <li>Discussions: Ask questions or share use cases.</li> <li>Documentation: Consult the user and developer guides.</li> </ul>"},{"location":"developer/contributing/#license","title":"License","text":"<p>SenoQuant is released under the BSD 3-Clause License. By contributing, you agree to license your contributions under the same license.</p>"},{"location":"developer/installation/","title":"Manual installation","text":"<p>This guide covers manual installation using conda, pip, and uv for users who prefer a command-line setup or are developing SenoQuant.</p> <p>Note: For most users, the installers are recommended as they simplify setup and ensure GPU support.</p>"},{"location":"developer/installation/#create-an-environment","title":"Create an environment","text":"<p>In your terminal (Command Prompt/PowerShell on Windows, Terminal on macOS/Linux), create and activate a new conda environment with Python 3.11.</p> <pre><code>conda create -n senoquant python=3.11\nconda activate senoquant\n</code></pre> <p>You should see <code>(senoquant)</code> at the beginning of your terminal prompt, indicating that the environment is active.</p>"},{"location":"developer/installation/#install-uv-and-napari","title":"Install uv and napari","text":"<p>We strongly recommend using <code>uv</code> instead of <code>pip</code> because standard pip often has difficulty solving complex dependencies. <code>uv</code> is also much faster.</p> <pre><code>pip install uv\nuv pip install pip-system-certs\nuv pip install \"napari[all]\"\n</code></pre> <p>Note: <code>pip-system-certs</code> enables Python to use your system's certificate store for SSL verification. This helps avoid certificate errors when downloading packages or models, especially on corporate networks or systems with custom certificate authorities.</p> <p>Alternatively, using standard <code>pip</code>:</p> <pre><code>pip install \"napari[all]\"\n</code></pre>"},{"location":"developer/installation/#install-senoquant","title":"Install SenoQuant","text":"<pre><code>uv pip install senoquant\n</code></pre> <p>Alternatively, using standard <code>pip</code> (not recommended. This might be fine for napari, but often fails for SenoQuant):</p> <pre><code>pip install senoquant\n</code></pre> <p>Warning (Windows): Installing via <code>pip</code>/<code>uv</code> may not pull a GPU-enabled PyTorch build on Windows. If you need GPU acceleration, use the Windows installer instead. Or, troubleshoot PyTorch installation manually by following the official PyTorch instructions.</p>"},{"location":"developer/installation/#optional-dependencies","title":"Optional dependencies","text":"<ul> <li><code>uv pip install senoquant[all]</code> for full stack.</li> </ul>"},{"location":"developer/installation/#launch","title":"Launch","text":"<p>Start napari from your terminal:</p> <pre><code>napari --with senoquant\n</code></pre> <p>The first launch of napari and the SenoQuant plugin will be slower as napari initializes and SenoQuant downloads model files (a few GBs) from Hugging Face. Subsequent launches will be faster as models are cached locally.</p> <p>Make sure the terminal remains open while using napari to keep it running. The terminal also displays useful info/warning/error messages.</p>"},{"location":"developer/installation/#development-installation","title":"Development installation","text":"<p>For development work, install SenoQuant from the repository in editable mode:</p> <pre><code>pip install uv\nuv pip install -e .\n</code></pre> <p>This allows you to make changes to the code and see them reflected immediately without reinstalling.</p>"},{"location":"developer/installer/","title":"Installers","text":"<p>This page documents the native installer pipelines for Windows and macOS, including build scripts, CI workflows, and troubleshooting notes.</p>"},{"location":"developer/installer/#overview","title":"Overview","text":"<p>SenoQuant provides native installers for Windows (<code>.exe</code>) and macOS (<code>.pkg</code>) that bundle the application with a dedicated Python environment.</p> <p>Both installers follow the same high-level pattern:</p> <ol> <li>Bundle the SenoQuant wheel, micromamba, and launcher scripts.</li> <li>Run a post-install script on first launch to create the Python environment.</li> <li>Install napari, PyTorch, and dependencies.</li> <li>Launch napari with the SenoQuant plugin.</li> </ol>"},{"location":"developer/installer/#version-management","title":"Version management","text":"<p>All installers read the version from <code>pyproject.toml</code> to ensure consistency.</p> <ul> <li>Python package: Uses <code>importlib.metadata.version(\"senoquant\")</code> with fallback.</li> <li>macOS installer: Extracts the version using <code>tomllib</code> during build.</li> <li>Windows installer: Reads the version using Inno Setup's <code>ReadIni()</code> function.</li> </ul> <p>To update the version across all installers, edit the <code>version</code> field in <code>pyproject.toml</code>.</p>"},{"location":"developer/installer/#macos-installer","title":"macOS installer","text":""},{"location":"developer/installer/#overview_1","title":"Overview","text":"<p>The macOS installer creates a native PKG that installs SenoQuant as an app bundle in <code>~/Applications/</code>.</p> <p>The app uses Application Support for writable data so it complies with macOS security policies.</p> <p>Key components:</p> <ul> <li>App bundle: <code>dist/macos-installer/SenoQuant.app</code>.</li> <li>PKG installer: <code>dist/macos-installer/SenoQuant-Installer.pkg</code>.</li> <li>Build script: <code>installer/macos/build_macos_installer.sh</code>.</li> <li>Launcher: <code>installer/macos/launch_senoquant.sh</code>.</li> <li>Post-install: <code>installer/macos/post_install.sh</code>.</li> <li>Environment config: <code>installer/macos/environment.macos.yml</code>.</li> </ul>"},{"location":"developer/installer/#build-pipeline","title":"Build pipeline","text":"<p>The installer is built via <code>.github/workflows/macos-installer.yml</code>:</p> <ol> <li>Build the SenoQuant wheel.</li> <li>Download micromamba for the target architecture (<code>arm64</code> or <code>x86_64</code>).</li> <li>Convert the SVG icon to ICNS format using <code>librsvg</code>.</li> <li>Assemble the app bundle with launcher scripts and resources.</li> <li>Create a component PKG with bundle relocation disabled.</li> <li>Package into a product PKG installer.</li> </ol>"},{"location":"developer/installer/#local-build-commands","title":"Local build commands","text":"<p>Prerequisites:</p> <ul> <li>macOS 10.15 or later.</li> <li>Python 3.11 or later.</li> <li>Build tools: <code>python -m pip install build</code>.</li> <li>Icon converter (recommended): <code>brew install librsvg</code>.</li> </ul> <p>From the repository root:</p> <pre><code>bash installer/macos/build_macos_installer.sh\n</code></pre> <p>The resulting PKG is written to <code>dist/macos-installer/SenoQuant-Installer.pkg</code>.</p>"},{"location":"developer/installer/#app-bundle-structure","title":"App bundle structure","text":"<pre><code>SenoQuant.app/\n  Contents/\n    Info.plist\n    MacOS/\n      launch_senoquant.sh\n    Resources/\n      senoquant.icns\n      post_install.sh\n      environment.macos.yml\n      tools/\n        micromamba\n      wheels/\n        senoquant-*.whl\n</code></pre>"},{"location":"developer/installer/#installation-flow","title":"Installation flow","text":"<ol> <li>The user runs the PKG, which installs to <code>~/Applications/SenoQuant.app</code>.</li> <li>The user launches the app, which runs <code>launch_senoquant.sh</code>.</li> <li>If launched from Finder, the launcher opens Terminal so logs are visible.</li> <li>If <code>~/Library/Application Support/SenoQuant/env</code> does not exist, the launcher runs post-install.</li> <li>Post-install creates the Python environment and installs dependencies.</li> <li>The launcher starts napari with the SenoQuant plugin.</li> </ol>"},{"location":"developer/installer/#writable-data-locations","title":"Writable data locations","text":"<p>To avoid self-modification inside <code>~/Applications</code>, SenoQuant writes runtime data to Application Support:</p> <ul> <li>Python environment: <code>~/Library/Application Support/SenoQuant/env</code>.</li> <li>Launch log: <code>~/Library/Application Support/SenoQuant/launch.log</code>.</li> <li>Post-install log: <code>~/Library/Application Support/SenoQuant/post_install.log</code>.</li> </ul> <p>The app bundle at <code>~/Applications/SenoQuant.app</code> remains read-only after installation.</p>"},{"location":"developer/installer/#pkg-configuration-details","title":"PKG configuration details","text":"<p>Install location:</p> <ul> <li><code>$HOME</code> (expands to <code>~/Applications/</code>).</li> </ul> <p>Component plist settings:</p> <ul> <li><code>BundleIsRelocatable: false</code>, which prevents macOS from moving the app.</li> <li><code>BundleOverwriteAction: upgrade</code>, which allows reinstallation.</li> </ul> <p>The build uses a staging directory (<code>pkg_staging/Applications/</code>) so <code>pkgbuild</code> only packages intended files.</p>"},{"location":"developer/installer/#architecture-support","title":"Architecture support","text":"<p>The build script auto-detects the host architecture and downloads the matching micromamba binary:</p> <ul> <li>Apple Silicon (<code>arm64</code>) gets ARM64 micromamba.</li> <li>Intel (<code>x86_64</code>) gets x86_64 micromamba.</li> </ul> <p>PyTorch is installed from standard channels and includes MPS support on Apple Silicon.</p>"},{"location":"developer/installer/#troubleshooting","title":"Troubleshooting","text":"<p>Icon not appearing.</p> <ul> <li>Install <code>librsvg</code>: <code>brew install librsvg</code>.</li> <li>Rebuild the installer.</li> <li>Alternatively, place <code>senoquant.icns</code> manually in <code>Resources/</code>.</li> </ul> <p>App does not launch.</p> <ul> <li>Check <code>~/Library/Application Support/SenoQuant/launch.log</code>.</li> <li>Check <code>~/Library/Application Support/SenoQuant/post_install.log</code>.</li> <li>Verify micromamba exists at <code>~/Applications/SenoQuant.app/Contents/Resources/tools/micromamba</code>.</li> </ul> <p>Terminal window does not open.</p> <ul> <li>The app uses AppleScript to open Terminal when launched from Finder.</li> <li>Try launching directly from Terminal using <code>~/Applications/SenoQuant.app/Contents/MacOS/launch_senoquant.sh</code>.</li> </ul> <p>Permission denied errors.</p> <ul> <li>Verify <code>launch_senoquant.sh</code> and <code>post_install.sh</code> are using the Application Support path.</li> </ul>"},{"location":"developer/installer/#windows-installer","title":"Windows installer","text":""},{"location":"developer/installer/#overview_2","title":"Overview","text":"<p>The Windows installer bundles a portable app directory and runs a post-install step to create the Python environment, install dependencies, and install the SenoQuant wheel.</p> <p>Key components:</p> <ul> <li>App bundle root: <code>dist/windows-installer/senoquant</code>.</li> <li>Inno Setup script: <code>installer/windows/senoquant.iss</code>.</li> <li>Build script: <code>installer/windows/build_windows_installer.ps1</code>.</li> <li>Post-install script: <code>installer/windows/post_install.ps1</code>.</li> </ul>"},{"location":"developer/installer/#build-pipeline_1","title":"Build pipeline","text":"<p>The installer is built via <code>.github/workflows/windows-installer.yml</code>:</p> <ol> <li>Build the SenoQuant wheel into the app bundle.</li> <li>Download and include <code>micromamba.exe</code>.</li> <li>Copy launchers, icons, and post-install scripts into the bundle.</li> <li>Package with Inno Setup into <code>SenoQuant-Installer.exe</code>.</li> </ol>"},{"location":"developer/installer/#local-build-commands_1","title":"Local build commands","text":"<p>Prerequisites:</p> <ul> <li>Python 3.11.</li> <li>Inno Setup (<code>ISCC</code>).</li> <li>ImageMagick (<code>magick</code> on <code>PATH</code>).</li> </ul> <p>From the repository root:</p> <ol> <li>Build the app bundle.</li> </ol> <pre><code>.\\installer\\windows\\build_windows_installer.ps1\n</code></pre> <ol> <li>Build the installer with Inno Setup.</li> </ol> <pre><code>$iscc = \"${env:ProgramFiles(x86)}\\Inno Setup 6\\ISCC.exe\"\n&amp; $iscc .\\installer\\windows\\senoquant.iss\n</code></pre> <p>The resulting installer is written to <code>installer/windows/Output/SenoQuant-Installer.exe</code>.</p>"},{"location":"developer/installer/#app-bundle-layout","title":"App bundle layout","text":"<p>The build script assembles this structure under <code>dist/windows-installer/senoquant</code>:</p> <pre><code>senoquant/\n  launch_senoquant.bat\n  launch_senoquant.ps1\n  post_install.ps1\n  senoquant_icon.ico\n  tools/\n    micromamba.exe\n  wheels/\n    senoquant-*.whl\n</code></pre>"},{"location":"developer/installer/#post-install-steps","title":"Post-install steps","text":"<p><code>post_install.ps1</code> runs after installation to:</p> <ul> <li>Create a Python 3.11 environment under <code>env/</code>.</li> <li>Install <code>napari[all]</code>, PyTorch (CUDA 12.1), and SenoQuant from the local wheel.</li> <li>Validate imports.</li> </ul> <p>The SenoQuant wheel pulls in runtime dependencies, including <code>senoquant-stardist-ext</code>.</p>"},{"location":"developer/installer/#troubleshooting_1","title":"Troubleshooting","text":"<p>Missing StarDist ops.</p> <ul> <li>Verify <code>senoquant-stardist-ext</code> is installed.</li> <li>Check compiled binaries under <code>env/Lib/site-packages/senoquant/tabs/segmentation/stardist_onnx_utils/_stardist/lib/</code>.</li> </ul> <p>Install location issues.</p> <ul> <li>Avoid <code>Program Files</code> to reduce permissions issues.</li> <li>Prefer user-local install paths, such as <code>%LOCALAPPDATA%</code>.</li> </ul> <p>GPU not detected.</p> <ul> <li>Verify CUDA toolkit installation.</li> <li>Check PyTorch with <code>python -c \"import torch; print(torch.cuda.is_available())\"</code>.</li> <li>Confirm the installer pulled the CUDA 12.1-compatible PyTorch build.</li> </ul>"},{"location":"developer/installer/#cicd-workflows","title":"CI/CD workflows","text":"<p>Both installers are built automatically via GitHub Actions:</p> <ul> <li>macOS: <code>.github/workflows/macos-installer.yml</code>.</li> <li>Windows: <code>.github/workflows/windows-installer.yml</code>.</li> </ul> <p>Triggers:</p> <ul> <li>Manual dispatch via <code>workflow_dispatch</code>.</li> <li>Automatic runs on release publication.</li> </ul> <p>Artifacts:</p> <ul> <li>Uploaded as build artifacts for testing.</li> <li>Automatically attached to GitHub releases.</li> </ul> <p>Verification:</p> <ul> <li>macOS: <code>pkgutil --check-signature</code> (unsigned PKG).</li> <li>Windows: successful Inno Setup build (signing is not configured by default).</li> </ul>"},{"location":"developer/models/","title":"Models, detectors, and prediction runners","text":"<p>This guide is the source-of-truth for adding:</p> <ul> <li>Segmentation models.</li> <li>Spot detectors.</li> <li>Prediction models.</li> </ul> <p>Discovery is folder-based and dynamic across all three systems, but metadata rules differ:</p> <ul> <li>Segmentation/Spots read UI schemas from <code>details.json</code>.</li> <li>Prediction models define UI directly in Qt code and do not require   <code>details.json</code>.</li> </ul>"},{"location":"developer/models/#how-discovery-works","title":"How discovery works","text":""},{"location":"developer/models/#segmentation-models","title":"Segmentation models","text":"<p>Folder location:</p> <p><code>src/senoquant/tabs/segmentation/models/&lt;model_name&gt;/</code></p> <p>Discovery behavior:</p> <ul> <li><code>SegmentationBackend.list_model_names(task=...)</code> scans subfolders.</li> <li>A model is shown for a task only if <code>details.json</code> has   <code>tasks.&lt;task&gt;.supported = true</code>.</li> <li>Runtime class loading looks for the first subclass of   <code>SenoQuantSegmentationModel</code> in <code>model.py</code>.</li> <li>If <code>model.py</code> is missing, the base class is used, but <code>run()</code> is not   implemented, so the model is not runnable.</li> </ul>"},{"location":"developer/models/#spot-detectors","title":"Spot detectors","text":"<p>Folder location:</p> <p><code>src/senoquant/tabs/spots/models/&lt;detector_name&gt;/</code></p> <p>Discovery behavior:</p> <ul> <li><code>SpotsBackend.list_detector_names()</code> scans subfolders.</li> <li>Runtime class loading looks for the first subclass of   <code>SenoQuantSpotDetector</code> in <code>model.py</code>.</li> <li>If <code>model.py</code> is missing, the base class is used, but <code>run()</code> is not   implemented, so the detector is not runnable.</li> </ul>"},{"location":"developer/models/#prediction-models","title":"Prediction models","text":"<p>Folder location:</p> <p><code>src/senoquant/tabs/prediction/models/&lt;model_name&gt;/</code></p> <p>Discovery behavior:</p> <ul> <li><code>PredictionBackend.list_model_names()</code> scans subfolders.</li> <li>Runtime class loading looks for the first subclass of   <code>SenoQuantPredictionModel</code> in <code>model.py</code>.</li> <li><code>display_order()</code> controls dropdown ordering (lower first).</li> <li>If <code>model.py</code> is missing, the base class is used, but <code>run()</code> is not   implemented, so the model is not runnable.</li> </ul>"},{"location":"developer/models/#metadata-schema-detailsjson-for-segmentation-and-spots","title":"Metadata schema (<code>details.json</code>) for segmentation and spots","text":"<p>Both segmentation and spots use a <code>settings</code> list to auto-build the UI. Manifest validation is enforced at load time via:</p> <ul> <li><code>src/senoquant/utils/model_details.schema.json</code></li> <li><code>src/senoquant/utils/model_details_schema.py</code></li> <li><code>SenoQuantSegmentationModel.load_details()</code> (requires <code>tasks</code>)</li> <li><code>SenoQuantSpotDetector.load_details()</code> (does not require <code>tasks</code>)</li> </ul> <p>If validation fails, model/detector loading raises a <code>ValueError</code> with the <code>details.json</code> path and validation message.</p>"},{"location":"developer/models/#required-top-level-keys-all-modelsdetectors","title":"Required top-level keys (all models/detectors)","text":"<ul> <li><code>name</code> (string)</li> <li><code>description</code> (string)</li> <li><code>version</code> (string)</li> <li><code>settings</code> (array)</li> </ul>"},{"location":"developer/models/#segmentation-only-requirement","title":"Segmentation-only requirement","text":"<ul> <li><code>tasks</code> object must be present and include both:</li> <li><code>tasks.nuclear</code></li> <li><code>tasks.cytoplasmic</code></li> </ul> <p>Supported setting types:</p> <ul> <li>Use <code>float</code>.</li> <li>Use <code>int</code>.</li> <li>Use <code>bool</code>.</li> </ul> <p>Supported dependency keys:</p> <ul> <li><code>enabled_by</code>: setting key of a controlling checkbox.</li> <li><code>disabled_by</code>: setting key of a controlling checkbox.</li> </ul> <p>Notes:</p> <ul> <li>In current UI code, <code>enabled_by</code> and <code>disabled_by</code> are treated as a   single key string.</li> <li><code>order</code> controls dropdown sorting (lower comes first).</li> <li>For <code>float</code> and <code>int</code> settings, <code>min</code>, <code>max</code>, and <code>default</code> are required.</li> <li>For <code>bool</code> settings, <code>default</code> is required.</li> </ul>"},{"location":"developer/models/#segmentation-specific-fields","title":"Segmentation-specific fields","text":"<p>Example:</p> <pre><code>{\n  \"name\": \"my_model\",\n  \"description\": \"Custom segmentation model.\",\n  \"version\": \"0.1.0\",\n  \"order\": 30,\n  \"tasks\": {\n    \"nuclear\": { \"supported\": true },\n    \"cytoplasmic\": {\n      \"supported\": true,\n      \"input_modes\": [\"cytoplasmic\", \"nuclear+cytoplasmic\", \"nuclear\"],\n      \"nuclear_channel_optional\": false\n    }\n  },\n  \"settings\": []\n}\n</code></pre> <p><code>input_modes</code> behavior:</p> <ul> <li><code>[\"cytoplasmic\"]</code>: cytoplasmic image only.</li> <li>Includes <code>nuclear+cytoplasmic</code>: uses both cytoplasmic and nuclear inputs.</li> <li><code>[\"nuclear\"]</code>: nuclear-only cytoplasmic model (no cytoplasmic image).</li> </ul>"},{"location":"developer/models/#spots-specific-fields","title":"Spots-specific fields","text":"<p>Example:</p> <pre><code>{\n  \"name\": \"my_detector\",\n  \"description\": \"Custom spot detector.\",\n  \"version\": \"0.1.0\",\n  \"order\": 30,\n  \"settings\": []\n}\n</code></pre>"},{"location":"developer/models/#prediction-model-conventions-no-detailsjson","title":"Prediction model conventions (no <code>details.json</code>)","text":"<p>Prediction models are code-driven. Required file:</p> <ul> <li><code>src/senoquant/tabs/prediction/models/&lt;model_name&gt;/model.py</code></li> </ul> <p>The tab-level controls are fixed in <code>src/senoquant/tabs/prediction/frontend.py</code>:</p> <ul> <li><code>Select model</code> dropdown.</li> <li><code>Model interface</code> box (model-defined widget).</li> <li><code>Run</code> button outside the box.</li> </ul> <p>Each model class should:</p> <ul> <li>Subclass <code>SenoQuantPredictionModel</code>.</li> <li>Optionally implement <code>display_order()</code> for dropdown sorting.</li> <li>Implement <code>build_widget(parent, viewer)</code> for model-specific controls.</li> <li>Implement <code>collect_widget_settings(settings_widget)</code> for serializable settings.</li> <li>Implement <code>run(viewer=..., settings=...)</code> returning prediction layer specs.</li> </ul> <p>Prediction backend accepts output layer specs as dicts or tuple-like payloads; see <code>PredictionBackend._normalize_layer_spec(...)</code> in <code>src/senoquant/tabs/prediction/backend.py</code>.</p>"},{"location":"developer/models/#add-a-new-segmentation-model","title":"Add a new segmentation model","text":"<ol> <li>Create the folder:    <code>src/senoquant/tabs/segmentation/models/my_model/</code>.</li> <li>Add <code>details.json</code> with <code>tasks</code> and <code>settings</code>.</li> <li>Add <code>model.py</code> with a subclass of <code>SenoQuantSegmentationModel</code>.</li> <li>Implement <code>run(self, **kwargs)</code> and return <code>{\"masks\": &lt;label_array&gt;}</code>.</li> <li>Restart napari and verify the model appears in the correct task dropdown.</li> </ol> <p>Minimal template:</p> <pre><code>from pathlib import Path\nfrom senoquant.tabs.segmentation.models.base import SenoQuantSegmentationModel\nfrom senoquant.utils import layer_data_asarray\n\n\nclass MySegmentationModel(SenoQuantSegmentationModel):\n    def __init__(self, models_root: Path | None = None) -&gt; None:\n        super().__init__(\"my_model\", models_root=models_root)\n\n    def run(self, **kwargs) -&gt; dict:\n        task = kwargs.get(\"task\")\n        settings = kwargs.get(\"settings\", {}) or {}\n\n        if task == \"nuclear\":\n            layer = kwargs.get(\"layer\")\n            image = layer_data_asarray(layer)\n        elif task == \"cytoplasmic\":\n            # Segmentation tab passes `cytoplasmic_layer`.\n            # Batch currently passes `layer` for the same input.\n            cyto_layer = kwargs.get(\"cytoplasmic_layer\") or kwargs.get(\"layer\")\n            nuclear_layer = kwargs.get(\"nuclear_layer\")\n            # pick the inputs your mode requires\n            image = layer_data_asarray(cyto_layer or nuclear_layer)\n        else:\n            raise ValueError(f\"Unsupported task: {task}\")\n\n        masks = my_segmentation_function(image, settings)\n        return {\"masks\": masks}\n</code></pre> <p>Important runtime contracts:</p> <ul> <li>Nuclear runs pass <code>task=\"nuclear\"</code> and <code>layer=&lt;Image&gt;</code>.</li> <li>Cytoplasmic runs pass <code>task=\"cytoplasmic\"</code> and:</li> <li>Segmentation tab: <code>cytoplasmic_layer</code>, optional <code>nuclear_layer</code>.</li> <li>Batch path: <code>layer</code>, optional <code>nuclear_layer</code>.</li> <li>nuclear-only models (<code>input_modes == [\"nuclear\"]</code>): <code>nuclear_layer</code>.</li> </ul>"},{"location":"developer/models/#add-a-new-spots-detector","title":"Add a new spots detector","text":"<ol> <li>Create the folder:    <code>src/senoquant/tabs/spots/models/my_detector/</code>.</li> <li>Add <code>details.json</code>.</li> <li>Add <code>model.py</code> with a subclass of <code>SenoQuantSpotDetector</code>.</li> <li>Implement <code>run(self, **kwargs)</code> and return <code>{\"mask\": &lt;label_array&gt;}</code>.</li> <li>Restart napari and verify detector appears in Spots dropdown.</li> </ol> <p>Minimal template:</p> <pre><code>from pathlib import Path\nfrom senoquant.tabs.spots.models.base import SenoQuantSpotDetector\nfrom senoquant.utils import layer_data_asarray\n\n\nclass MyDetector(SenoQuantSpotDetector):\n    def __init__(self, models_root: Path | None = None) -&gt; None:\n        super().__init__(\"my_detector\", models_root=models_root)\n\n    def run(self, **kwargs) -&gt; dict:\n        layer = kwargs.get(\"layer\")\n        settings = kwargs.get(\"settings\", {}) or {}\n        image = layer_data_asarray(layer)\n        mask = my_spot_detector(image, settings)\n        return {\"mask\": mask}\n</code></pre> <p>Important runtime contracts:</p> <ul> <li>Detector runs receive <code>layer</code> and <code>settings</code>.</li> <li>Output layer naming and metadata are handled in <code>SpotsTab</code>, not in the   detector.</li> <li>Both Spots tab and Batch apply optional post-detection filtering through   <code>_filter_labels_by_size(...)</code> (<code>src/senoquant/tabs/spots/frontend.py</code>).</li> <li><code>min_size</code> / <code>max_size</code> values are treated as diameter thresholds (pixels):   2D uses effective area (<code>pi * (d/2)^2</code>), 3D uses effective volume   (<code>(4/3) * pi * (d/2)^3</code>).</li> </ul>"},{"location":"developer/models/#add-a-new-prediction-model","title":"Add a new prediction model","text":"<ol> <li>Create the folder:    <code>src/senoquant/tabs/prediction/models/my_model/</code>.</li> <li>Add <code>model.py</code> with a subclass of <code>SenoQuantPredictionModel</code>.</li> <li>Implement <code>build_widget()</code>, <code>collect_widget_settings()</code>, and <code>run()</code>.</li> <li>Return output as layer specs under a <code>layers</code> list.</li> <li>Restart napari and verify the model appears in Select model.</li> </ol> <p>Minimal template:</p> <pre><code>from qtpy.QtWidgets import QLabel, QVBoxLayout, QWidget\nfrom senoquant.tabs.prediction.models.base import SenoQuantPredictionModel\n\n\nclass MyPredictionWidget(QWidget):\n    def __init__(self, viewer, parent: QWidget | None = None) -&gt; None:\n        super().__init__(parent)\n        self._viewer = viewer\n        layout = QVBoxLayout()\n        layout.addWidget(QLabel(\"Configure my prediction model\"))\n        self.setLayout(layout)\n\n    def values(self) -&gt; dict[str, object]:\n        return {\"scale\": 1.0}\n\n\nclass MyPredictionModel(SenoQuantPredictionModel):\n    def __init__(self, models_root=None) -&gt; None:\n        super().__init__(\"my_model\", models_root=models_root)\n\n    def build_widget(self, parent=None, viewer=None):\n        return MyPredictionWidget(viewer=viewer, parent=parent)\n\n    def collect_widget_settings(self, settings_widget=None) -&gt; dict[str, object]:\n        if settings_widget is None:\n            return {}\n        return settings_widget.values()\n\n    def run(self, **kwargs) -&gt; dict:\n        settings = kwargs.get(\"settings\", {})\n        return {\n            \"layers\": [\n                {\n                    \"data\": ...,  # numpy array\n                    \"type\": \"image\",\n                    \"name\": \"my_prediction_output\",\n                }\n            ],\n            \"settings\": settings,\n        }\n</code></pre>"},{"location":"developer/models/#quick-validation-checklist","title":"Quick validation checklist","text":"<ul> <li>Folder name, class constructor name, and <code>super(\"&lt;name&gt;\")</code> all match.</li> <li>Segmentation/Spots: <code>details.json</code> passes <code>model_details.schema.json</code> validation.</li> <li>Segmentation manifests include both <code>tasks.nuclear</code> and <code>tasks.cytoplasmic</code>.</li> <li><code>run()</code> returns expected keys:</li> <li>Segmentation: <code>masks</code>.</li> <li>Spots: <code>mask</code>.</li> <li>Prediction: <code>layers</code> (or a sequence normalized by backend).</li> <li>Settings keys in code match <code>details.json</code> keys (segmentation/spots only).</li> <li>New model/detector/prediction runner appears in UI and can run on a sample image.</li> </ul>"},{"location":"developer/models/#stardist-onnx-notes","title":"StarDist ONNX notes","text":"<p>The StarDist conversion utilities and compiled extension still live under:</p> <ul> <li><code>src/senoquant/tabs/segmentation/stardist_onnx_utils/</code>.</li> <li><code>stardist_ext/</code>.</li> </ul> <p>For conversion workflow details, see <code>docs/developer/stardist-onnx.md</code>. For packaging details, see <code>docs/developer/packaging.md</code>.</p>"},{"location":"developer/packaging/","title":"Packaging and releases","text":"<p>SenoQuant is a setuptools-based Python package with a separate compiled extension for StarDist NMS and 3D label rendering. The project provides native installers for Windows and macOS.</p>"},{"location":"developer/packaging/#core-package","title":"Core package","text":"<ul> <li>Metadata lives in <code>pyproject.toml</code>.</li> <li>Version is centralized in <code>pyproject.toml</code> and read by all build systems.</li> <li>The plugin exposes napari entry points via <code>src/senoquant/napari.yaml</code>.</li> </ul>"},{"location":"developer/packaging/#native-installers","title":"Native installers","text":"<p>SenoQuant provides native installers that bundle the application with all dependencies:</p> <ul> <li>Windows: Inno Setup-based <code>.exe</code> installer (see Installers documentation).</li> <li>macOS: PKG installer targeting <code>~/Applications</code> (see Installers documentation).</li> </ul> <p>Both installers:</p> <ul> <li>Include a micromamba-based Python 3.11 environment.</li> <li>Install napari, PyTorch, and SenoQuant on first launch.</li> <li>Are built automatically via GitHub Actions and attached to releases.</li> </ul>"},{"location":"developer/packaging/#stardist-extension","title":"StarDist extension","text":"<p>Source for the compiled extension lives in <code>stardist_ext/</code>. The extension is published to PyPI as <code>senoquant-stardist-ext</code>. To build the wheel locally (for development or custom builds):</p> <pre><code>pip install -U scikit-build-core\npip wheel ./stardist_ext -w ./wheelhouse\n</code></pre> <p>Install the generated wheel:</p> <pre><code>pip install ./wheelhouse/senoquant_stardist_ext-*.whl\n</code></pre> <p>The main package depends on <code>senoquant-stardist-ext</code>, so distribution pipelines should ensure wheels are built for target platforms and uploaded to PyPI.</p>"},{"location":"developer/prediction/","title":"Prediction models","text":"<p>This guide covers the Prediction tab framework for running computer-vision models that predict senescence-associated features from napari images.</p> <p>Prediction code lives in:</p> <ul> <li><code>src/senoquant/tabs/prediction/frontend.py</code></li> <li><code>src/senoquant/tabs/prediction/backend.py</code></li> <li><code>src/senoquant/tabs/prediction/models/base.py</code></li> <li><code>src/senoquant/tabs/prediction/models/</code></li> </ul>"},{"location":"developer/prediction/#tab-ui-contract","title":"Tab UI contract","text":"<p>The tab-level UI is intentionally minimal and fixed:</p> <ul> <li>Select model dropdown at the top.</li> <li>Model interface group box that hosts model-defined Qt controls.</li> <li>Run button outside the model interface box.</li> </ul> <p>The base tab does not define a generic image/layer selector. Each model owns its own input controls in its widget.</p>"},{"location":"developer/prediction/#discovery-and-loading","title":"Discovery and loading","text":"<p>Model discovery is folder-based under:</p> <ul> <li><code>src/senoquant/tabs/prediction/models/&lt;model_name&gt;/</code></li> </ul> <p><code>PredictionBackend.list_model_names()</code> scans these folders and sorts by:</p> <ol> <li><code>model.display_order()</code> (lower first).</li> <li>Model name.</li> </ol> <p>Model class loading behavior (<code>PredictionBackend.get_model()</code>):</p> <ul> <li>Loads <code>&lt;model_name&gt;/model.py</code> dynamically.</li> <li>Uses the first subclass of <code>SenoQuantPredictionModel</code> found.</li> <li>Falls back to <code>SenoQuantPredictionModel</code> when no concrete class is found.</li> </ul> <p>Unlike segmentation/spots, prediction models do not require <code>details.json</code>.</p>"},{"location":"developer/prediction/#base-class-contract","title":"Base class contract","text":"<p>Subclass <code>SenoQuantPredictionModel</code> from:</p> <ul> <li><code>src/senoquant/tabs/prediction/models/base.py</code></li> </ul> <p>Key methods:</p> <ul> <li><code>display_order(self) -&gt; float | None</code>: optional selector ordering.</li> <li><code>build_widget(self, parent=None, viewer=None) -&gt; QWidget | None</code>: create model UI.</li> <li><code>collect_widget_settings(self, settings_widget=None) -&gt; dict[str, object]</code>: serialize UI state.</li> <li><code>run(self, **kwargs) -&gt; dict</code>: execute model and return output layer specs.</li> </ul> <p>Run payload currently includes:</p> <ul> <li><code>viewer</code>: napari viewer instance.</li> <li><code>settings</code>: serialized settings from <code>collect_widget_settings()</code>.</li> </ul>"},{"location":"developer/prediction/#output-contract-and-normalization","title":"Output contract and normalization","text":"<p>Prediction output is handled by <code>PredictionBackend.run_model()</code> and <code>PredictionBackend.push_layers_to_viewer()</code>.</p> <p>A model can return:</p> <ul> <li><code>{\"layers\": [...]}</code> (preferred), optionally with <code>\"settings\"</code>.</li> <li>A raw sequence of layer specs (wrapped as <code>layers</code> by the backend).</li> </ul> <p>Each layer spec may be:</p> <ul> <li>Mapping form:</li> <li>required: <code>data</code></li> <li>optional: <code>type</code> (<code>image</code>, <code>labels</code>, <code>points</code>, ...), <code>kwargs</code>, and any extra napari kwargs</li> <li>Tuple/list form:</li> <li><code>(data,)</code></li> <li><code>(data, kwargs)</code></li> <li><code>(data, kwargs, layer_type)</code></li> </ul> <p>If no layer name is supplied, backend assigns:</p> <ul> <li><code>&lt;source_or_model&gt;_&lt;model_name&gt;_prediction_&lt;index&gt;</code></li> </ul> <p>For each added layer, backend appends run metadata via <code>senoquant.utils.append_run_metadata(...)</code>:</p> <ul> <li><code>task=\"prediction\"</code></li> <li><code>runner_type=\"prediction_model\"</code></li> <li><code>runner_name=&lt;model_name&gt;</code></li> <li>serialized <code>settings</code></li> </ul>"},{"location":"developer/prediction/#demo-model-reference","title":"Demo model reference","text":"<p>Current placeholder model:</p> <ul> <li><code>src/senoquant/tabs/prediction/models/demo_model/model.py</code></li> </ul> <p>It demonstrates:</p> <ul> <li>building a custom Qt widget</li> <li>selecting a napari image layer</li> <li>collecting widget settings</li> <li>running simple inference logic</li> <li>returning an image layer payload</li> </ul>"},{"location":"developer/prediction/#add-a-new-prediction-model","title":"Add a new prediction model","text":"<ol> <li>Create folder:    <code>src/senoquant/tabs/prediction/models/my_model/</code></li> <li>Add <code>model.py</code> with a <code>SenoQuantPredictionModel</code> subclass.</li> <li>Implement <code>build_widget()</code>, <code>collect_widget_settings()</code>, and <code>run()</code>.</li> <li>Restart napari and verify it appears in Select model.</li> </ol> <p>Minimal template:</p> <pre><code>from qtpy.QtWidgets import QLabel, QVBoxLayout, QWidget\n\nfrom senoquant.tabs.prediction.models.base import SenoQuantPredictionModel\n\n\nclass MyModelWidget(QWidget):\n    def __init__(self, viewer, parent=None) -&gt; None:\n        super().__init__(parent)\n        self._viewer = viewer\n        layout = QVBoxLayout()\n        layout.addWidget(QLabel(\"Configure my model here\"))\n        self.setLayout(layout)\n\n    def values(self) -&gt; dict[str, object]:\n        return {\"example\": 1}\n\n\nclass MyModel(SenoQuantPredictionModel):\n    def __init__(self, models_root=None) -&gt; None:\n        super().__init__(\"my_model\", models_root=models_root)\n\n    def build_widget(self, parent=None, viewer=None):\n        return MyModelWidget(viewer=viewer, parent=parent)\n\n    def collect_widget_settings(self, settings_widget=None) -&gt; dict[str, object]:\n        if settings_widget is None:\n            return {}\n        return settings_widget.values()\n\n    def run(self, **kwargs) -&gt; dict:\n        viewer = kwargs.get(\"viewer\")\n        settings = kwargs.get(\"settings\", {})\n        # Compute prediction output from viewer + settings.\n        return {\n            \"layers\": [\n                {\n                    \"data\": ...,  # numpy array\n                    \"type\": \"image\",\n                    \"name\": \"my_prediction_map\",\n                }\n            ]\n        }\n</code></pre>"},{"location":"developer/prediction/#test-coverage","title":"Test coverage","text":"<p>Prediction tests live in:</p> <ul> <li><code>tests/senoquant/tabs/prediction/test_frontend.py</code></li> <li><code>tests/senoquant/tabs/prediction/test_backend.py</code></li> </ul> <p>When you change prediction behavior, update both frontend and backend coverage as needed.</p>"},{"location":"developer/quantification-features/","title":"Quantification features","text":"<p>Quantification features live in <code>src/senoquant/tabs/quantification/features</code>. Each feature owns two things:</p> <ul> <li>UI controls (<code>build()</code> in a <code>SenoQuantFeature</code> subclass).</li> <li>Export logic (<code>export()</code> that writes files into a temp directory).</li> </ul>"},{"location":"developer/quantification-features/#how-feature-loading-works","title":"How feature loading works","text":"<ul> <li><code>get_feature_registry()</code> in <code>src/senoquant/tabs/quantification/features/__init__.py</code>   imports all submodules and collects subclasses of <code>SenoQuantFeature</code>.</li> <li>The feature picker uses each class's <code>feature_type</code> string.</li> <li>Feature type order in the UI is sorted by the class attribute <code>order</code>.</li> <li>Feature state is stored in <code>FeatureConfig</code>:</li> <li><code>feature_id</code> (stable id).</li> <li><code>name</code> (user-facing name).</li> <li><code>type_name</code> (feature type).</li> <li><code>data</code> (feature-specific payload, subclass of <code>FeatureData</code>).</li> </ul>"},{"location":"developer/quantification-features/#runtime-and-output-routing","title":"Runtime and output routing","text":"<ul> <li><code>QuantificationTab</code> builds one <code>FeatureUIContext</code> per row and instantiates a   feature handler (<code>feature_handler</code>) from the registry.</li> <li><code>QuantificationBackend.process()</code> calls <code>handler.export(temp_dir, export_format)</code>   for each configured feature.</li> <li>Output files are moved into a feature-specific folder under the chosen output   root:</li> <li>Folder name = sanitized feature <code>name</code> (or <code>type_name</code> when name is blank).</li> <li>Lowercase, spaces become <code>_</code>, and non-alphanumeric characters are replaced.</li> <li>If <code>export()</code> returns an empty iterable, the backend moves all files found in   that feature's temp directory.</li> </ul>"},{"location":"developer/quantification-features/#add-a-new-quantification-feature","title":"Add a new quantification feature","text":""},{"location":"developer/quantification-features/#1-create-a-feature-package","title":"1) Create a feature package","text":"<p>Create <code>src/senoquant/tabs/quantification/features/&lt;your_feature&gt;/</code> and add at least:</p> <ul> <li><code>config.py</code> for dataclasses.</li> <li><code>feature.py</code> for the UI handler.</li> <li><code>export.py</code> for file generation.</li> </ul>"},{"location":"developer/quantification-features/#2-define-feature-data-payload","title":"2) Define feature data payload","text":"<p>In <code>config.py</code>, define dataclasses that inherit from <code>FeatureData</code> (directly or indirectly).</p> <pre><code>from dataclasses import dataclass, field\nfrom senoquant.tabs.quantification.features.base import FeatureData\n\n\n@dataclass\nclass MyFeatureData(FeatureData):\n    labels: list[str] = field(default_factory=list)\n    enabled: bool = True\n</code></pre>"},{"location":"developer/quantification-features/#3-implement-the-feature-handler","title":"3) Implement the feature handler","text":"<p>In <code>feature.py</code>, subclass <code>SenoQuantFeature</code> and set a unique <code>feature_type</code>.</p> <pre><code>from pathlib import Path\nfrom senoquant.tabs.quantification.features.base import SenoQuantFeature\nfrom .export import export_my_feature\n\n\nclass MyFeature(SenoQuantFeature):\n    feature_type = \"My feature\"\n    order = 30\n\n    def build(self) -&gt; None:\n        # Build controls and persist values into self._state.data\n        ...\n\n    def export(self, temp_dir: Path, export_format: str):\n        return export_my_feature(\n            self._state,\n            temp_dir,\n            viewer=self._tab._viewer,\n            export_format=export_format,\n        )\n</code></pre>"},{"location":"developer/quantification-features/#4-register-feature-data-factory","title":"4) Register feature data factory","text":"<p>Update <code>FEATURE_DATA_FACTORY</code> in <code>src/senoquant/tabs/quantification/features/__init__.py</code>:</p> <pre><code>FEATURE_DATA_FACTORY = {\n    \"Markers\": MarkerFeatureData,\n    \"Spots\": SpotsFeatureData,\n    \"My feature\": MyFeatureData,\n}\n</code></pre> <p>Without this, switching to your feature type creates a generic <code>FeatureData</code> object and your typed config is lost.</p>"},{"location":"developer/quantification-features/#5-add-batch-settings-bundle-serialization-support","title":"5) Add batch settings-bundle serialization support","text":"<p>If the feature should work with Batch settings persistence, update <code>src/senoquant/tabs/batch/config.py</code>:</p> <ul> <li><code>_serialize_feature_data()</code> to add a case for your data class.</li> <li><code>_deserialize_feature_data()</code> to reconstruct your data class.</li> </ul> <p>If you skip this step, bundle payloads will serialize as <code>{\"type\": \"Unknown\"}</code> and reload without your feature settings.</p>"},{"location":"developer/quantification-features/#6-add-tests","title":"6) Add tests","text":"<p>Recommended test updates:</p> <ul> <li>Registry and data factory: <code>tests/senoquant/tabs/quantification/features/test_registry.py</code>.</li> <li>Export behavior: add tests under <code>tests/senoquant/tabs/quantification/features/</code>.</li> <li>Batch settings-bundle round-trip: <code>tests/senoquant/tabs/batch/test_config.py</code>.</li> </ul>"},{"location":"developer/quantification-features/#built-in-export-patterns-consolidated-reference-columns","title":"Built-in export patterns (consolidated reference columns)","text":"<p>This section replaces the old standalone marker cross-reference document.</p>"},{"location":"developer/quantification-features/#markers-export","title":"Markers export","text":"<p><code>src/senoquant/tabs/quantification/features/marker/export.py</code> currently writes:</p> <ul> <li>One table per selected segmentation: <code>&lt;segmentation&gt;.csv|xlsx</code>.</li> <li>Shared feature metadata bundle: <code>feature_settings.json</code>.</li> <li>Uses top-level <code>feature_settings</code> + <code>segmentation_runs</code> keys from the     <code>senoquant.settings</code> envelope.</li> <li>Threshold settings are embedded in <code>feature_settings.config</code>.</li> </ul> <p>Reference columns added in marker rows:</p> <ul> <li><code>file_path</code> (from first selected channel image metadata path, when present).</li> <li><code>segmentation_type</code> (<code>nuclear</code> or <code>cytoplasmic</code>).</li> <li><code>overlaps_with</code> (cross-segmentation overlap ids, <code>seg_name_label_id;...</code>).</li> </ul>"},{"location":"developer/quantification-features/#spots-export","title":"Spots export","text":"<p><code>src/senoquant/tabs/quantification/features/spots/export.py</code> currently writes, depending on segmentation availability:</p> <ul> <li>With one or more valid segmentations:</li> <li><code>&lt;segmentation&gt;_cells.csv|xlsx</code>.</li> <li><code>&lt;segmentation&gt;_spots.csv|xlsx</code>.</li> <li>Without valid segmentations:</li> <li><code>all_spots.csv|xlsx</code>.</li> <li>Shared feature metadata bundle: <code>feature_settings.json</code>.</li> </ul> <p>Reference and relationship columns:</p> <ul> <li><code>file_path</code> is included in both cells and spots tables.</li> <li>Cells table includes <code>overlaps_with</code> for cross-segmentation overlaps.</li> <li>Spots rows are always preserved; with segmentation configured, rows include   <code>within_segmentation</code> (<code>1</code> inside segmentation, <code>0</code> outside) and <code>cell_id=0</code>   for outside spots.</li> <li>If <code>export_colocalization</code> is enabled:</li> <li>The spots table includes <code>colocalizes_with</code>.</li> <li>The cells table includes <code>colocalization_event_count</code>.</li> </ul> <p>Channel label behavior in spots export:</p> <ul> <li>Use <code>channel.name</code> (trimmed) if provided.</li> <li>Fall back to <code>channel.channel</code> when name is blank.</li> </ul>"},{"location":"developer/quantification-features/#common-pitfalls","title":"Common pitfalls","text":"<ul> <li><code>feature_type</code> mismatch across class, factory key, and serialized <code>\"type\"</code> string.</li> <li>Returning no files from <code>export()</code> and forgetting to write files into <code>temp_dir</code>.</li> <li>Adding a new <code>FeatureData</code> subclass but not wiring Batch serialize/deserialize.</li> </ul>"},{"location":"developer/repo-map/","title":"Repo map","text":"<p>This page summarizes the current repository layout and where core behavior is implemented.</p>"},{"location":"developer/repo-map/#top-level-folders","title":"Top-level folders","text":"<ul> <li><code>src/senoquant/</code>: package source.</li> <li><code>tests/</code>: pytest suite.</li> <li><code>docs/</code>: MkDocs docs (<code>user/</code>, <code>developer/</code>, <code>api/</code>).</li> <li><code>stardist_ext/</code>: compiled StarDist extension source/package.</li> <li><code>_vendor/ufish/</code>: vendored U-FISH code used by spot detection support.</li> <li><code>installer/</code>: installer build assets and scripts.</li> <li><code>res/</code>: extra resources used by packaging/install flows.</li> </ul>"},{"location":"developer/repo-map/#package-entry-points-srcsenoquant","title":"Package entry points (<code>src/senoquant</code>)","text":"<ul> <li><code>napari.yaml</code>: napari plugin registration (widget + reader).</li> <li><code>__init__.py</code>: exports plugin symbols.</li> <li><code>_widget.py</code>: main tabbed widget (<code>SenoQuantWidget</code>) wiring all tabs.</li> <li><code>_reader.py</code>: napari reader entrypoint.</li> <li><code>reader/core.py</code>: BioIO-backed reader implementation (scene selection, channel splitting, metadata).</li> <li><code>utils/utils.py</code>: shared utility helpers.</li> <li><code>utils/settings_bundle.py</code>: unified <code>senoquant.settings</code> envelope helpers.</li> <li><code>utils/model_details.schema.json</code>: JSON Schema for model/detector <code>details.json</code> manifests.</li> <li><code>utils/model_details_schema.py</code>: manifest validation helpers used by segmentation/spots base classes.</li> </ul>"},{"location":"developer/repo-map/#tab-modules-srcsenoquanttabs","title":"Tab modules (<code>src/senoquant/tabs</code>)","text":"<ul> <li><code>segmentation/</code>: segmentation tab UI/backend and segmentation models.</li> <li><code>segmentation/_frontend/</code>: split frontend mixins and widgets used by segmentation tab.</li> <li><code>segmentation/models/</code>: built-in models (<code>default_2d</code>, <code>default_3d</code>, <code>cpsam</code>, <code>nuclear_dilation</code>, <code>perinuclear_rings</code>).</li> <li><code>segmentation/stardist_onnx_utils/</code>: StarDist runtime helpers, conversion/runtime support, vendored StarDist/CSBDeep compatibility code.</li> <li><code>spots/</code>: spots tab UI/backend and detector orchestration.</li> <li><code>spots/models/</code>: built-in detectors (<code>rmp</code>, <code>ufish</code>) plus shared detector base classes.</li> <li><code>prediction/</code>: prediction tab UI/backend and prediction model orchestration.</li> <li><code>prediction/models/</code>: built-in placeholder model (<code>demo_model</code>) and shared prediction model base class.</li> <li><code>quantification/</code>: quantification tab UI/backend.</li> <li><code>quantification/features/</code>: feature system (<code>Markers</code>, <code>Spots</code>) with per-feature config/UI/export modules.</li> <li><code>visualization/</code>: visualization tab UI/backend.</li> <li><code>visualization/plots/</code>: plot handler system (<code>Spatial Plot</code>, <code>UMAP</code>, <code>Double Expression</code>).</li> <li><code>batch/</code>: batch UI/backend/config/io/layer shims.</li> <li><code>settings/</code>: Settings tab save/load orchestration.</li> </ul>"},{"location":"developer/repo-map/#common-tab-patterns","title":"Common tab patterns","text":"<ul> <li><code>frontend.py</code>: Qt widgets, signal wiring, and user interactions.</li> <li><code>backend.py</code>: processing logic and discovery/orchestration.</li> <li><code>models/&lt;name&gt;/details.json</code>: metadata-driven settings schema used by segmentation/spots.</li> <li><code>models/&lt;name&gt;/model.py</code>: runtime implementation class (segmentation, spots, prediction).</li> <li>Prediction models do not require <code>details.json</code>; model UI is defined directly in code.</li> </ul>"},{"location":"developer/repo-map/#test-layout-highlights-testssenoquant","title":"Test layout highlights (<code>tests/senoquant</code>)","text":"<ul> <li><code>tabs/test_ui_smoke.py</code>: tab/widget smoke tests.</li> <li><code>tabs/segmentation/</code>: frontend/backend/model tests for segmentation.</li> <li><code>tabs/spots/</code>: frontend/backend/detector/filter tests for spots.</li> <li><code>tabs/prediction/</code>: frontend/backend/model tests for prediction.</li> <li><code>tabs/quantification/</code>: backend + feature export and UI tests.</li> <li><code>tabs/visualization/</code>: backend/plot registry/handler tests.</li> <li><code>tabs/batch/</code>: config/backend/io/frontend integration tests.</li> <li><code>tabs/settings/</code>: settings backend/frontend round-trip tests.</li> </ul>"},{"location":"developer/stardist-onnx/","title":"StarDist ONNX conversion","text":"<p>This guide documents the StarDist-to-ONNX conversion utility used by the default StarDist segmentation models.</p>"},{"location":"developer/stardist-onnx/#location","title":"Location","text":"<p>Conversion code lives under:</p> <ul> <li><code>src/senoquant/tabs/segmentation/stardist_onnx_utils/onnx_framework/convert/</code></li> </ul> <p>Main entry points:</p> <ul> <li><code>convert_pretrained_2d(...)</code></li> <li><code>convert_pretrained_3d(...)</code></li> <li><code>convert_model_to_onnx(...)</code></li> <li>CLI module: <code>convert/cli.py</code></li> </ul>"},{"location":"developer/stardist-onnx/#prerequisites","title":"Prerequisites","text":"<p>Conversion requires TensorFlow + tf2onnx in your environment.</p> <p>Recommended extras for conversion workflows:</p> <ul> <li><code>tensorflow</code></li> <li><code>tf2onnx</code></li> <li>compatible <code>protobuf</code> (if conversion errors reference protobuf mismatches)</li> </ul>"},{"location":"developer/stardist-onnx/#cli-usage","title":"CLI usage","text":"<p>The converter is currently exposed as a Python module CLI.</p> <p>Convert pretrained 2D model:</p> <pre><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.convert.cli \\\n  --dim 2d \\\n  --model 2D_versatile_fluo \\\n  --output ./onnx_models \\\n  --opset 18\n</code></pre> <p>Convert pretrained 3D model:</p> <pre><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.convert.cli \\\n  --dim 3d \\\n  --model 3D_demo \\\n  --output ./onnx_models \\\n  --opset 18\n</code></pre> <p><code>--output</code> can be either:</p> <ul> <li>a directory (auto filename is generated), or</li> <li>a full <code>.onnx</code> file path.</li> </ul>"},{"location":"developer/stardist-onnx/#converter-cli-flags-convertcli","title":"Converter CLI flags (<code>convert.cli</code>)","text":"<p>Command:</p> <p><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.convert.cli</code></p> Argument Type Default What it does <code>--dim</code> choice: <code>2</code>, <code>3</code>, <code>2d</code>, <code>3d</code> <code>2d</code> Selects 2D vs 3D StarDist model conversion path. <code>--model</code> string <code>None</code> Pretrained model alias or local StarDist model directory path. If omitted, uses built-in default model for selected <code>--dim</code>. <code>--output</code> path <code>.</code> Output destination. Directory =&gt; auto-generated filename; <code>.onnx</code> path =&gt; exact output file. <code>--opset</code> int <code>18</code> ONNX opset version used during export via <code>tf2onnx</code>. <p>Default model mapping when <code>--model</code> is omitted:</p> <ul> <li><code>--dim 2d</code> / <code>2</code> -&gt; <code>2D_versatile_fluo</code></li> <li><code>--dim 3d</code> / <code>3</code> -&gt; <code>3D_demo</code></li> </ul>"},{"location":"developer/stardist-onnx/#python-api-usage","title":"Python API usage","text":"<pre><code>from senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.convert import (\n    convert_pretrained_2d,\n    convert_pretrained_3d,\n)\n\npath2d = convert_pretrained_2d(\"2D_versatile_fluo\", \"./onnx_models\", opset=18)\npath3d = convert_pretrained_3d(\"3D_demo\", \"./onnx_models\", opset=18)\nprint(path2d, path3d)\n</code></pre> <p>You can also pass a StarDist model instance to <code>convert_model_to_onnx(...)</code>.</p>"},{"location":"developer/stardist-onnx/#output-filenames-and-placement","title":"Output filenames and placement","text":"<p>When <code>--output</code> points to a directory, generated filenames follow:</p> <ul> <li><code>stardist2d_&lt;model_name&gt;.onnx</code></li> <li><code>stardist3d_&lt;model_name&gt;.onnx</code></li> </ul> <p>For automatic discovery by SenoQuant default models, place ONNX files in the model folders, preferably:</p> <ul> <li><code>src/senoquant/tabs/segmentation/models/default_2d/onnx_models/default_2d.onnx</code></li> <li><code>src/senoquant/tabs/segmentation/models/default_3d/onnx_models/default_3d.onnx</code></li> </ul>"},{"location":"developer/stardist-onnx/#optional-inspection-helpers","title":"Optional inspection helpers","text":"<p>After conversion, you can inspect model IO/divisibility:</p> <pre><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.inspect.cli \\\n  ./onnx_models/stardist2d_2D_versatile_fluo.onnx \\\n  --ndim 2\n</code></pre> <p>And estimate receptive field/overlap:</p> <pre><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.inspect.rf_cli \\\n  ./onnx_models/stardist2d_2D_versatile_fluo.onnx \\\n  --ndim 2 --shape 256 256\n</code></pre>"},{"location":"developer/stardist-onnx/#inspect-cli-flags-inspectcli","title":"Inspect CLI flags (<code>inspect.cli</code>)","text":"<p>Command:</p> <p><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.inspect.cli</code></p> Argument Type Default What it does <code>model</code> path (positional) required Path to the ONNX model to inspect. <code>--ndim</code> choice: <code>2</code>, <code>3</code> <code>None</code> Optional dimensionality hint for <code>div_by</code> inference."},{"location":"developer/stardist-onnx/#receptive-field-cli-flags-inspectrf_cli","title":"Receptive-field CLI flags (<code>inspect.rf_cli</code>)","text":"<p>Command:</p> <p><code>python -m senoquant.tabs.segmentation.stardist_onnx_utils.onnx_framework.inspect.rf_cli</code></p> Argument Type Default What it does <code>model</code> path (positional) required Path to the ONNX model. <code>--ndim</code> choice: <code>2</code>, <code>3</code> <code>None</code> Optional dimensionality hint for receptive-field estimation. <code>--shape</code> int list <code>None</code> Spatial probe size, e.g. <code>--shape 256 256</code> (2D) or <code>--shape 64 64 64</code> (3D). <code>--eps</code> float <code>0.0</code> Sensitivity threshold for numerical change detection during RF probing."},{"location":"developer/stardist-onnx/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p><code>TensorFlow is required to export StarDist models.</code></p> <ul> <li>Install TensorFlow in the active env.</li> </ul> </li> <li> <p><code>tf2onnx is required to export StarDist models.</code></p> <ul> <li>Install <code>tf2onnx</code> in the same env.</li> </ul> </li> <li> <p>protobuf-related conversion errors</p> <ul> <li>Reinstall/align protobuf with your TensorFlow/tf2onnx stack.</li> </ul> </li> <li> <p>Runtime inference errors after conversion</p> <ul> <li>Verify model IO with <code>inspect.cli</code>.</li> <li>Verify output model path matches SenoQuant model lookup conventions.</li> </ul> </li> </ul>"},{"location":"developer/visualization/","title":"Visualization tab","text":"<p>This guide covers architecture and extension points for the Visualization tab.</p>"},{"location":"developer/visualization/#module-layout","title":"Module layout","text":"<p>Visualization code lives in:</p> <ul> <li><code>src/senoquant/tabs/visualization/frontend.py</code></li> <li><code>src/senoquant/tabs/visualization/backend.py</code></li> <li><code>src/senoquant/tabs/visualization/plots/</code></li> </ul> <p>Key responsibilities:</p> <ul> <li><code>frontend.py</code>:</li> <li>Builds the Qt UI (<code>VisualizationTab</code>).</li> <li>Collects marker selections and thresholds.</li> <li>Runs preview generation and save actions.</li> <li><code>backend.py</code>:</li> <li>Orchestrates plot handler execution.</li> <li>Routes temporary outputs into final files.</li> <li><code>plots/</code>:</li> <li>Contains plot handler implementations.</li> <li>Handles dynamic plot discovery and registration.</li> </ul>"},{"location":"developer/visualization/#plot-discovery-and-state","title":"Plot discovery and state","text":"<p>Plot classes are discovered dynamically by <code>get_plot_registry()</code> in <code>src/senoquant/tabs/visualization/plots/__init__.py</code>.</p> <p>Discovery behavior:</p> <ul> <li>Imports all modules under <code>plots/</code>.</li> <li>Collects subclasses of <code>SenoQuantPlot</code>.</li> <li>Uses each class <code>plot_type</code> as the dropdown key.</li> <li>Sorts by class attribute <code>order</code>.</li> </ul> <p>Plot runtime state is stored in <code>PlotConfig</code>:</p> <ul> <li><code>plot_id</code>: stable identifier for the configured row.</li> <li><code>type_name</code>: selected plot type.</li> <li><code>data</code>: plot-specific payload (<code>PlotData</code> subclass).</li> </ul> <p><code>PLOT_DATA_FACTORY</code> maps plot type names to typed <code>PlotData</code> classes.</p>"},{"location":"developer/visualization/#runtime-flow","title":"Runtime flow","text":"<p>Single run flow:</p> <ol> <li><code>VisualizationTab._process_plots()</code> gathers selected markers and thresholds.</li> <li>It calls <code>VisualizationBackend.process(..., save=False, cleanup=False)</code>.</li> <li>Backend calls each handler's <code>plot(temp_dir, input_path, export_format, markers, thresholds)</code>.</li> <li>Returned paths are stored in <code>VisualizationResult.plot_outputs</code>.</li> <li>Frontend renders preview files from those output paths.</li> </ol> <p>Save flow:</p> <ol> <li><code>VisualizationTab._save_plots()</code> calls <code>VisualizationBackend.save_result(...)</code>.</li> <li>Backend routes/copies files to the chosen output directory.</li> <li>Output paths in <code>PlotExportResult.outputs</code> are updated to final destinations.</li> </ol>"},{"location":"developer/visualization/#plot-handler-contract","title":"Plot handler contract","text":"<p>Plot handlers subclass <code>SenoQuantPlot</code> from <code>src/senoquant/tabs/visualization/plots/base.py</code>.</p> <p>Required class attributes:</p> <ul> <li><code>plot_type</code>: user-facing plot name in the dropdown.</li> <li><code>order</code>: integer sort key in the registry.</li> </ul> <p>Required methods:</p> <ul> <li><code>build(self)</code>: build plot-specific controls (optional if no custom UI).</li> <li><code>plot(self, temp_dir, input_path, export_format, markers=None, thresholds=None)</code>:   generate outputs and return an iterable of <code>Path</code>.</li> </ul> <p>Behavior notes:</p> <ul> <li>Handlers may return explicit output paths, or return <code>[]</code> and write files into <code>temp_dir</code>.</li> <li>Backend will fallback to routing all files in <code>temp_dir</code> when explicit paths are not returned.</li> </ul>"},{"location":"developer/visualization/#adding-a-new-visualization-plot","title":"Adding a new visualization plot","text":"<ol> <li>Add a module under <code>src/senoquant/tabs/visualization/plots/</code>.</li> <li>Define a <code>PlotData</code> subclass if typed state is needed.</li> <li>Implement a <code>SenoQuantPlot</code> subclass with <code>plot_type</code> and <code>order</code>.</li> <li>Implement <code>plot(...)</code> to produce outputs in the provided <code>temp_dir</code>.</li> <li>Register typed data in <code>PLOT_DATA_FACTORY</code> when applicable.</li> <li>Add tests under <code>tests/senoquant/tabs/visualization/</code>.</li> </ol> <p>Minimal skeleton:</p> <pre><code>from pathlib import Path\nfrom typing import Iterable\n\nfrom senoquant.tabs.visualization.plots.base import PlotData, SenoQuantPlot\n\n\nclass MyPlotData(PlotData):\n    pass\n\n\nclass MyPlot(SenoQuantPlot):\n    plot_type = \"My Plot\"\n    order = 30\n\n    def build(self) -&gt; None:\n        pass\n\n    def plot(\n        self,\n        temp_dir: Path,\n        input_path: Path,\n        export_format: str,\n        markers: list[str] | None = None,\n        thresholds: dict[str, float] | None = None,\n    ) -&gt; Iterable[Path]:\n        output_file = temp_dir / f\"my_plot.{export_format}\"\n        # write output_file\n        return [output_file]\n</code></pre>"},{"location":"developer/visualization/#dependency-notes","title":"Dependency notes","text":"<p>Dependency loading is currently mixed:</p> <ul> <li><code>SpatialPlot</code> and <code>DoubleExpressionPlot</code> import <code>pandas</code>/<code>matplotlib</code>   inside <code>plot()</code>.</li> <li><code>UMAPPlot</code> imports <code>pandas</code>, <code>matplotlib</code>, and <code>umap-learn</code> at module load   time (<code>src/senoquant/tabs/visualization/plots/umap.py</code>).</li> </ul> <p>When adding new dependencies:</p> <ul> <li>Prefer local imports inside handler methods.</li> <li>Gracefully return <code>[]</code> with a clear message when dependency import fails.</li> </ul>"},{"location":"user/batch/","title":"Batch processing","text":"<p>The Batch tab runs segmentation, spot detection, and quantification across folders of images.</p>"},{"location":"user/batch/#interface-overview","title":"Interface overview","text":""},{"location":"user/batch/#input-section","title":"Input section","text":"<p>Controls:</p> <ul> <li>Input folder (browse field): Select the folder containing input images.</li> <li>Extensions (text field): Comma-separated file extensions to include.</li> <li>Include subfolders (checkbox): Recursively scan nested folders.</li> <li>Process all scenes (checkbox): Process all scenes in multi-scene files.</li> </ul> <p>Behavior notes:</p> <ul> <li>If the extensions field is empty, all files are considered.</li> <li>Extensions are normalized to lowercase and a leading dot is added if missing.</li> <li>By default, the extensions field is pre-filled with common image formats.</li> <li>Batch settings are saved/loaded from the Settings tab using   <code>senoquant_settings.json</code>.</li> </ul>"},{"location":"user/batch/#channels-section","title":"Channels section","text":"<p>Use channel mappings to define reusable channel names for all dropdowns in the tab.</p> <p>Controls:</p> <ul> <li>Add channel (button): Add a new channel row.</li> <li>Name (text field): Channel display name (for example, <code>DAPI</code>).</li> <li>Index (spin box): Zero-based channel index in the source image.</li> <li>Delete (button): Remove that mapping row.</li> </ul> <p>Behavior notes:</p> <ul> <li>If Name is left blank, Batch uses the index as the name (for example, <code>0</code>).</li> <li>Channel names from this section drive nuclear/cytoplasmic/spot channel selectors and quantification layer choices.</li> </ul>"},{"location":"user/batch/#segmentation-section","title":"Segmentation section","text":""},{"location":"user/batch/#nuclear-segmentation-controls","title":"Nuclear segmentation controls","text":"<ul> <li>Run nuclear segmentation (checkbox): Enable or disable nuclear segmentation.</li> <li>Nuclear model (dropdown): Select a nuclear model.</li> <li>Nuclear channel (dropdown): Select the image channel for nuclear segmentation.</li> <li>Edit nuclear settings (button): Open the model settings dialog.</li> </ul>"},{"location":"user/batch/#cytoplasmic-segmentation-controls","title":"Cytoplasmic segmentation controls","text":"<ul> <li>Run cytoplasmic segmentation (checkbox): Enable or disable cytoplasmic segmentation.</li> <li>Cytoplasmic model (dropdown): Select a cytoplasmic model.</li> <li>Cytoplasmic channel (dropdown): Select the image channel for cytoplasmic segmentation.</li> <li>Nuclear channel (dropdown): Select a nuclear channel when required by the selected model.</li> <li>Edit cytoplasmic settings (button): Open the model settings dialog.</li> </ul> <p>Behavior notes:</p> <ul> <li>Cytoplasmic models that support <code>nuclear+cytoplasmic</code> input enable the nuclear channel selector.</li> <li>For models where nuclear input is optional, the label updates to <code>Nuclear channel (optional)</code> and includes <code>(none)</code> as a valid choice.</li> <li>For models where nuclear input is required, the label updates to <code>Nuclear channel (required)</code>.</li> <li>Batch settings dialogs mirror Segmentation-tab model settings.</li> <li>Some model behaviors are fixed and not shown as controls:</li> <li>StarDist (<code>default_2d</code>/<code>default_3d</code>) normalization is always enabled.</li> <li>CPSAM auto-detects 2D vs 3D from input dimensionality and always normalizes.</li> </ul>"},{"location":"user/batch/#spot-detection-section","title":"Spot detection section","text":"<p>Controls:</p> <ul> <li>Run spot detection (checkbox): Enable or disable spot detection.</li> <li>Spot detector (dropdown): Select the spot detector.</li> <li>Edit spot settings (button): Open detector settings.</li> <li>Minimum diameter (px) (spin box): Minimum post-detection filter value in pixels (<code>0</code> means no minimum filter).</li> <li>Maximum diameter (px) (spin box): Maximum post-detection filter value in pixels (<code>0</code> means no maximum filter).</li> <li>Add spot channel (button): Add a spot channel row.</li> <li>Spot channel row: Channel dropdown plus Delete button.</li> </ul> <p>Behavior notes:</p> <ul> <li>Spot filtering is applied after detector output.</li> <li>Internally, <code>min_size</code> and <code>max_size</code> are interpreted as diameter thresholds in pixels and converted to effective area (2D) or volume (3D) before filtering labels.</li> <li>If spot detection is enabled, at least one spot channel must be selected before run.</li> <li>Batch spot-settings dialogs mirror Spots-tab detector settings.</li> <li>Detector behaviors fixed internally and not shown as controls:</li> <li>RMP angle spacing is fixed to <code>5</code> and denoising is always enabled.</li> <li>UFISH denoising is always enabled.</li> </ul>"},{"location":"user/batch/#quantification-section","title":"Quantification section","text":"<p>The Batch tab embeds the Quantification feature editor with batch-safe options.</p> <p>Controls:</p> <ul> <li>Run quantification (checkbox): Enable or disable quantification.</li> <li>Embedded feature editor: Add and configure Markers or Spots features.</li> </ul> <p>Batch-mode differences from the Quantification tab:</p> <ul> <li>Output-path controls are hidden.</li> <li>The Process button is hidden.</li> <li>ROI configuration is disabled.</li> <li>Threshold controls are disabled.</li> <li>Quantification format is set in the Batch Output section.</li> </ul>"},{"location":"user/batch/#output-section","title":"Output section","text":"<p>Controls:</p> <ul> <li>Output folder (browse field): Destination root for batch outputs.</li> <li>Quantification format (dropdown): <code>xlsx</code> or <code>csv</code>.</li> <li>Overwrite existing outputs (checkbox): Control behavior when output folders already exist.</li> </ul> <p>Behavior notes:</p> <ul> <li>If output folder is left empty, Batch defaults to <code>&lt;input_folder&gt;/batch-output</code>.</li> <li>If overwrite is off and a target output folder already exists, that item is skipped.</li> </ul>"},{"location":"user/batch/#run-section","title":"Run section","text":"<p>Controls:</p> <ul> <li>Run batch (button): Start batch processing.</li> <li>Progress bar: Shows percent completion.</li> <li>Status label: Shows current status and per-item progress text.</li> </ul> <p>Behavior notes:</p> <ul> <li>Processing runs in a background thread.</li> <li>Progress messages include file name and scene when relevant.</li> <li>Completion reports processed, failed, and skipped item counts.</li> <li>You must enable at least one processing path (segmentation, spots, or quantification).</li> <li>If spot detection is enabled, at least one spot channel is required.</li> </ul>"},{"location":"user/batch/#settings-integration","title":"Settings integration","text":"<p>Batch no longer has dedicated Load profile / Save profile buttons. Instead:</p> <ul> <li>Use the Settings tab to save or load unified settings bundles.</li> <li>When loading a settings bundle, Batch state is applied automatically if   the file contains a <code>batch_job</code> payload.</li> <li>During batch runs, SenoQuant writes a <code>senoquant_settings.json</code> file in the   batch output root so run configuration is captured with results.</li> </ul>"},{"location":"user/batch/#processing-behavior","title":"Processing behavior","text":"<p>For each discovered image file (and each scene, if scene processing is enabled), Batch runs steps in this order:</p> <ol> <li>Nuclear segmentation (if enabled).</li> <li>Cytoplasmic segmentation (if enabled).</li> <li>Spot detection (if enabled).</li> <li>Quantification (if enabled and features are configured).</li> </ol> <p>Batch continues processing remaining items even if one item fails.</p>"},{"location":"user/batch/#output-structure","title":"Output structure","text":""},{"location":"user/batch/#per-image-output-folders","title":"Per-image output folders","text":"<p>Batch writes outputs under:</p> <p><code>&lt;output_folder&gt;/&lt;image_base_name&gt;/</code></p> <p>If Process all scenes is enabled:</p> <p><code>&lt;output_folder&gt;/&lt;image_base_name&gt;/&lt;scene_name&gt;/</code></p>"},{"location":"user/batch/#segmentation-and-spots-output-names","title":"Segmentation and spots output names","text":"<ul> <li>Nuclear masks: <code>&lt;channel&gt;_&lt;model&gt;_nuc_labels.npy</code>.</li> <li>Cytoplasmic masks: <code>&lt;channel&gt;_&lt;model&gt;_cyto_labels.npy</code>.</li> <li>Spot masks: <code>&lt;channel&gt;_&lt;detector&gt;_spot_labels.npy</code>.</li> </ul>"},{"location":"user/batch/#quantification-output-layout","title":"Quantification output layout","text":"<p>Quantification outputs are written into feature folders inside the same per-image (or per-scene) folder:</p> <p><code>&lt;output_folder&gt;/&lt;image_or_scene&gt;/&lt;feature_name_sanitized&gt;/</code></p> <p>Within each feature folder:</p> <ul> <li>Markers feature: One file per segmentation.</li> <li>Spots feature:</li> <li>With segmentation(s): <code>&lt;segmentation_label&gt;_cells.&lt;format&gt;</code> and <code>&lt;segmentation_label&gt;_spots.&lt;format&gt;</code>.</li> <li>Without segmentation: <code>all_spots.&lt;format&gt;</code>.</li> <li>Shared feature metadata: <code>feature_settings.json</code>.</li> </ul> <p>Feature folder names are normalized to lowercase and spaces become underscores.</p>"},{"location":"user/batch/#example-layout","title":"Example layout","text":"<pre><code>batch-output/\n  senoquant_settings.json\n  sample_01/\n    dapi_default_2d_nuc_labels.npy\n    fitc_ufish_spot_labels.npy\n    if_markers/\n      dapi_default_2d_nuc_labels.xlsx\n      feature_settings.json\n    if_spots/\n      dapi_default_2d_nuc_labels_cells.xlsx\n      dapi_default_2d_nuc_labels_spots.xlsx\n      feature_settings.json\n  sample_02/\n    Scene_0/\n      ...\n    Scene_1/\n      ...\n</code></pre>"},{"location":"user/batch/#tips","title":"Tips","text":"<ul> <li>Keep channel mapping complete before configuring feature dropdowns.</li> <li>Verify detector/model settings on one representative image before full batch runs.</li> <li>Use the Settings tab save/load flow to reuse segmentation, spot, and   batch configurations.</li> <li>Leave overwrite off when resuming interrupted runs.</li> </ul>"},{"location":"user/data/","title":"Data &amp; File Formats","text":"<p>SenoQuant uses BioIO as its primary file reader. BioIO automatically selects the appropriate reader plugin based on the file format, providing seamless support for most common microscopy and image formats.</p>"},{"location":"user/data/#reader-behavior","title":"Reader behavior","text":"<p>When you open a file in napari with SenoQuant installed:</p> <ol> <li>Format detection: BioIO automatically determines the appropriate reader plugin for the file.</li> <li>Scene processing: Multi-scene files (e.g., <code>.lif</code>, <code>.czi</code>) have each scene loaded as separate layers.</li> <li>Channel splitting: Each channel within a scene becomes an individual image layer in napari.</li> <li>Metadata preservation: Physical pixel sizes, scene names, channel information, file path, etc., are stored in layer metadata.</li> </ol>"},{"location":"user/data/#scenes-and-channels","title":"Scenes and channels","text":""},{"location":"user/data/#multi-scene-files","title":"Multi-scene files","text":"<p>Files with multiple scenes (e.g., Leica <code>.lif</code>, Zeiss <code>.czi</code>) are processed as follows:</p> <ul> <li>Each scene is loaded as a separate set of layers.</li> <li>Layer names include the scene identifier (e.g., <code>image.lif - Scene 1</code>).</li> <li>Scene metadata is accessible in the layer properties.</li> </ul>"},{"location":"user/data/#channel-organization","title":"Channel organization","text":"<ul> <li>Each channel becomes a dedicated image layer.</li> <li>Channels are automatically assigned colormaps from a predefined cycle (blue, green, red, cyan, magenta, yellow).</li> <li>Layer names include channel indices for identification (e.g., <code>image.tif - Channel 0</code>).</li> <li>Blending mode is set to \"additive\" for multi-channel visualization.</li> </ul>"},{"location":"user/data/#supported-file-formats","title":"Supported file formats","text":"<p>SenoQuant supports the following file patterns:</p>"},{"location":"user/data/#common-formats","title":"Common formats","text":"<ul> <li>TIFF: <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>.</li> <li>ND2: <code>.nd2</code> (Nikon NIS-Elements).</li> <li>LIF: <code>.lif</code> (Leica Image Format).</li> <li>CZI: <code>.czi</code> (Zeiss).</li> <li>Zarr: <code>.zarr</code> (chunked array storage).</li> </ul>"},{"location":"user/data/#additional-formats","title":"Additional formats","text":"<p>See the BioIO documentation for a full list of supported formats via plugins. SenoQuant includes:</p> <ul> <li>bioio-czi</li> <li>bioio-dv</li> <li>bioio-imageio</li> <li>bioio-lif</li> <li>bioio-nd2</li> <li>bioio-ome-tiff</li> <li>bioio-ome-zarr</li> <li>bioio-sldy</li> <li>bioio-tifffile</li> <li>bioio-tiff-glob</li> </ul> <p>Note: Actual support depends on installed BioIO reader plugins. If BioIO cannot open a file, napari will attempt to use other available readers. Additional formats may be supported upon request.</p>"},{"location":"user/data/#metadata-accessibility","title":"Metadata accessibility","text":"<p>Layer metadata includes:</p> <ul> <li><code>bioio_metadata</code>: Full BioIO metadata structure.</li> <li><code>scene_info</code>: Scene identifier, index, and total scene count.</li> <li><code>path</code>: Original file path.</li> <li><code>channel_index</code>: Zero-based channel index.</li> <li><code>physical_pixel_sizes</code>: Physical dimensions in micrometers (X, Y, Z).</li> </ul> <p>Access metadata programmatically\"</p> <pre><code>layer = viewer.layers[\"image.tif - Channel 0\"]\nmetadata = layer.metadata\nscene_name = metadata[\"scene_info\"][\"scene_name\"]\npixel_size_x = metadata[\"physical_pixel_sizes\"][\"X\"]\n</code></pre>"},{"location":"user/data/#dimensionality","title":"Dimensionality","text":"<p>SenoQuant supports:</p> <ul> <li>2D images: Single Z-plane (YX data).</li> <li>3D images: Z-stacks (ZYX data).</li> <li>Multi-channel: Any number of channels per scene.</li> </ul>"},{"location":"user/data/#fallback-readers","title":"Fallback readers","text":"<p>If BioIO cannot determine a reader for your file:</p> <ol> <li>SenoQuant returns <code>None</code> from its reader function.</li> <li>napari automatically tries other installed readers.</li> <li>Use napari's built-in readers, or install plugins from napari's Plugin Manager as alternatives.</li> </ol> <p>If your format is not currently supported by the SenoQuant reader (for example, Akoya <code>QPTIFF</code>), we recommend converting it to OME-TIFF using NGFF-Converter, then opening the converted output in SenoQuant.</p> <p>Warning: Metadata-based quantification features (e.g., ones associated with physical units) will not work correctly if the SenoQuant reader is bypassed.</p>"},{"location":"user/installation/","title":"Installation","text":"<p>SenoQuant targets Python 3.11 and is designed to run inside napari.</p>"},{"location":"user/installation/#system-requirements","title":"System requirements","text":"<p>Before installing, make sure your system meets these requirements:</p> <ul> <li>A 64-bit operating system.</li> <li>A stable internet connection for first-time setup and model downloads.</li> <li>Enough free disk space for the Python environment, dependencies, and cached models (several GB).</li> </ul>"},{"location":"user/installation/#platform-support","title":"Platform support","text":"<ul> <li>Windows installer: 64-bit Windows (<code>x64</code>).</li> <li>macOS installer: macOS 10.15 or later.</li> <li>macOS hardware: Apple Silicon and Intel are both supported.</li> <li>Linux: Installer support is under construction.</li> </ul>"},{"location":"user/installation/#runtime-notes","title":"Runtime notes","text":"<ul> <li>Manual installs require Python 3.11.</li> <li>Windows can use GPU acceleration when a compatible PyTorch/CUDA setup is available.</li> <li>Apple Silicon can use MPS acceleration.</li> <li>Intel Macs currently run CPU-only.</li> </ul>"},{"location":"user/installation/#recommended-hardware","title":"Recommended hardware","text":"<p>These are practical recommendations for smooth use. They are not strict hard limits.</p> <ul> <li>CPU: 8 cores (or better) is recommended. 4 cores is workable for small 2D datasets.</li> <li>System RAM:</li> <li>16 GB minimum for light 2D work.</li> <li>32 GB recommended for routine multi-channel analysis.</li> <li>64 GB or more recommended for large 3D stacks and batch processing.</li> <li>Discrete GPU (Windows/Linux, recommended):</li> <li>NVIDIA GPU with CUDA support.</li> <li>8 GB VRAM recommended for most 2D workflows.</li> <li>12 GB or more VRAM recommended for larger images, 3D workflows, or high-throughput batch runs.</li> <li>Storage: SSD strongly recommended, with at least 50-100 GB free for environments, model cache, and outputs.</li> </ul> <p>Reference build targets:</p> <ul> <li>Good baseline workstation: 8-core CPU, 32 GB RAM, NVIDIA RTX-class GPU with 8 GB VRAM.</li> <li>Heavy 3D or high-throughput batch workstation: 12+ core CPU, 64 GB RAM, NVIDIA RTX-class GPU with 12-24 GB VRAM.</li> </ul>"},{"location":"user/installation/#installer-recommended","title":"Installer (recommended)","text":""},{"location":"user/installation/#windows","title":"Windows","text":"<p>The Windows installer is the easiest and most reliable way to install SenoQuant on Windows.</p> <ol> <li>Download the Windows installer (<code>.exe</code>) from the latest GitHub Release.</li> <li>Run the installer and choose an install location (user profile locations like LocalAppData are recommended).</li> <li>After installation completes, launch SenoQuant from the Start Menu or the desktop icon.</li> </ol> <p>Note: The installer sets up a dedicated conda environment and installs GPU-enabled PyTorch where available. This avoids the common issue where <code>pip</code> installs CPU-only PyTorch on Windows.</p> <p>The first launch of napari and the SenoQuant plugin will be slower as napari initializes and SenoQuant downloads model files (a few GBs) from Hugging Face. Subsequent launches will be faster as models are cached locally.</p>"},{"location":"user/installation/#macos","title":"macOS","text":"<p>The macOS installer provides a native PKG installer that sets up SenoQuant with all dependencies.</p> <ol> <li>Download the macOS installer (<code>.pkg</code>) from the latest GitHub Release.</li> <li>Double-click the PKG file and follow the installation prompts.</li> <li>The app installs to <code>~/Applications/SenoQuant.app</code>.</li> <li>Launch SenoQuant from Spotlight, Launchpad, or your Applications folder.</li> </ol> <p>Note: On first launch, a Terminal window opens showing installation progress. The initial setup creates a Python environment and installs napari, PyTorch, and SenoQuant dependencies. This may take 5-10 minutes depending on your internet connection. Subsequent launches will be much faster.</p> <p>The Python environment and logs are stored in <code>~/Library/Application Support/SenoQuant/</code>, while the app bundle remains at <code>~/Applications/SenoQuant.app</code>.</p> <p>Architecture Support:</p> <ul> <li>Apple Silicon (M1/M2/M3): Includes MPS (Metal Performance Shaders) acceleration for improved performance.</li> <li>Intel Macs: CPU-only operation.</li> </ul>"},{"location":"user/installation/#linux","title":"Linux","text":"<p>Under construction</p>"},{"location":"user/installation/#manual-installation-condapipuv","title":"Manual installation (conda/pip/uv)","text":"<p>For manual installation using conda, pip, and uv\u2014whether you're on Windows, macOS, Linux, or doing development work\u2014see the Installation guide in the Developer Guide.</p> <p>Warning: Manual installations via <code>pip</code>/<code>uv</code> may not pull a GPU-enabled PyTorch build on Windows. If you need GPU acceleration, use the Windows Installer above. Or, troubleshoot PyTorch installation manually by following the official PyTorch instructions.</p>"},{"location":"user/prediction/","title":"Prediction","text":"<p>The Prediction tab is where SenoQuant hosts computer-vision models for senescence-associated feature prediction.</p> <p>Use this tab to run models that produce prediction layers in napari (for example, per-pixel score maps or model-derived feature images).</p> <p>The Prediction tab is designed to be developer-friendly. It's model-agnostic, modular, and flexible, allowing each model to define its own user interface and input selection method. This enables support for a wide range of prediction tasks and model architectures without being constrained by a fixed set of input controls.</p> <p>Currently, the Prediction tab includes a <code>demo_model</code> placeholder to illustrate the model interface and output structure. If you're interested in contributing a new prediction model, see the developer guide for implementation details.</p>"},{"location":"user/prediction/#interface-overview","title":"Interface overview","text":"<p>The tab has three parts:</p> <ul> <li>Select model (dropdown): choose a prediction model discovered from   <code>src/senoquant/tabs/prediction/models/</code>.</li> <li>Model interface (box): displays the model-defined Qt widget.</li> <li>Run (button): executes the selected model with current widget settings.   This button sits outside the Model interface box.</li> </ul> <p>Unlike Segmentation/Spots, the base Prediction tab does not define input-layer controls. Each model widget decides how inputs are selected from the viewer.</p> <p>Tab-level UI source:</p> <ul> <li><code>src/senoquant/tabs/prediction/frontend.py</code></li> </ul>"},{"location":"user/prediction/#current-placeholder-model-demo_model","title":"Current placeholder model: <code>demo_model</code>","text":"<p><code>demo_model</code> is a minimal example implementation in:</p> <ul> <li><code>src/senoquant/tabs/prediction/models/demo_model/model.py</code></li> </ul> <p>Its UI contains:</p> <ul> <li>Image layer (dropdown): picks a napari image layer.</li> <li>Multiplier (spinbox): scales image values.</li> </ul> <p>Runtime behavior:</p> <ol> <li>Reads the selected image layer.</li> <li>Multiplies all values by the multiplier.</li> <li>Clips to the source dtype limits (<code>uint8</code>, <code>uint16</code>, float, etc.).</li> <li>Adds output as <code>&lt;layer_name&gt;_demo_model</code>.</li> </ol>"},{"location":"user/prediction/#output-and-metadata","title":"Output and metadata","text":"<p>Prediction outputs are added as napari layers by:</p> <ul> <li><code>src/senoquant/tabs/prediction/backend.py</code></li> </ul> <p>Each output layer receives run metadata in <code>layer.metadata.run_history</code> with:</p> <ul> <li>task: <code>prediction</code></li> <li>runner type: <code>prediction_model</code></li> <li>runner name: selected model name</li> <li>settings: serialized widget settings</li> </ul>"},{"location":"user/prediction/#for-developers","title":"For developers","text":"<p>To add a new prediction model, place it under:</p> <ul> <li><code>src/senoquant/tabs/prediction/models/&lt;model_name&gt;/model.py</code></li> </ul> <p>and subclass:</p> <ul> <li><code>senoquant.tabs.prediction.models.base.SenoQuantPredictionModel</code></li> </ul> <p>See the developer guide:</p> <ul> <li><code>docs/developer/prediction.md</code></li> </ul>"},{"location":"user/quantification/","title":"Quantification","text":"<p>The Quantification tab extracts measurements from segmented images and exports them to spreadsheet files.</p>"},{"location":"user/quantification/#interface-overview","title":"Interface overview","text":""},{"location":"user/quantification/#main-interface-controls","title":"Main interface controls","text":"<ul> <li>Add feature (button): Create a new quantification feature.</li> <li>Features list (panel): Shows all configured features with name, type, and delete button.</li> <li>Output folder (browse field): Select folder where results will be saved.</li> <li>Save name (text field): Name for the output subfolder (optional).</li> <li>Format (dropdown): Choose <code>xlsx</code> or <code>csv</code> for export format.</li> <li>Process and save (button): Execute quantification and save results.</li> </ul>"},{"location":"user/quantification/#feature-configuration-dialog","title":"Feature configuration dialog","text":"<p>When you click Add feature, a numbered feature appears in the Features list:</p> <p>Common fields:</p> <ul> <li>Name: Custom name for this feature (e.g., <code>IF markers</code>, <code>IF spots</code>).</li> <li>Feature type (dropdown): Select \"Markers\" or \"Spots\".</li> <li>Delete (button): Remove this feature.</li> </ul>"},{"location":"user/quantification/#feature-types","title":"Feature types","text":"<p>The quantification tab organizes exports by Features. A feature defines what to quantify and how. In the current version, two feature types are supported: Markers and Spots. This is based on common data types in senescence research:</p> <ul> <li>Markers: Measure intensity-based markers (e.g., IF markers) within nuclear/cytoplasmic masks.</li> <li>Spots: Count spots and analyze colocalization within cell masks.</li> </ul>"},{"location":"user/quantification/#markers-feature","title":"Markers feature","text":"<p>Measures channel intensity and morphological properties within segmentation labels.</p> <p>Add channels popup:</p> <p>Segmentation section:</p> <ul> <li>Add segmentation: Add a segmentation layer.</li> <li>Labels (dropdown per row): Select a labels layer (nuclear or cytoplasmic masks).</li> <li>Delete (per row): Remove this segmentation.</li> </ul> <p>Each segmentation added here will be applied to all channels in this feature. SenoQuant will export one cell x marker table per segmentation.</p> <p>Channels section:</p> <ul> <li>Add channel: Add an image channel.</li> <li>Channel (dropdown per row): Select an image layer to measure intensities from.</li> <li> <p>Set threshold (checkbox per row): Enable intensity thresholding.</p> <ul> <li>Threshold (slider): Threshold level (enabled when checkbox checked). The values set here are linked to the napari layer contrast limits for easy visualization. Mean intensities outside and within the thresholded region will marked in the output files.</li> <li> <p>Method (dropdown): Various thresholding methods:</p> <ul> <li><code>Manual</code>: Set threshold using slider.</li> <li><code>Otsu</code>: Automatic Otsu thresholding.</li> <li><code>Yen</code>: Automatic Yen thresholding.</li> <li><code>Li</code>: Automatic Li thresholding.</li> <li><code>Isodata</code>: Automatic Isodata thresholding.</li> <li><code>Triangle</code>: Automatic Triangle thresholding.</li> </ul> <p>Click the \"Auto threshold\" button to compute the threshold using the selected automatic method. For more details on these methods, refer to the skimage documentation.</p> </li> <li> <p>Delete (per row): Remove this channel.</p> </li> </ul> </li> </ul> <p>Closing the popup or clicking Save will save the settings.</p> <p>ROI section:</p> <p>Enabled by checking the ROIs checkbox in the main feature configuration box.</p> <ul> <li>Add ROI: Add a region of interest filter.</li> <li>Layer (dropdown): Select a Shapes layer.</li> <li>Type (dropdown): \"Include\" (mark overlapping as 1 in output) or \"Exclude\" (mark overlapping as 0 in output).</li> <li>Delete: Remove this ROI.</li> </ul>"},{"location":"user/quantification/#exported-columns-markers","title":"Exported columns (Markers)","text":"<p>Morphological metrics (2D images):</p> <ul> <li><code>morph_area</code> - Area in pixels.</li> <li><code>morph_area_um2</code> - Area in \u00b5m\u00b2 (if pixel sizes available).</li> <li><code>morph_perimeter</code> - Perimeter in pixels.</li> <li><code>morph_perimeter_crofton</code> - Crofton perimeter estimate.</li> <li><code>morph_circularity</code> - 4\u03c0\u00b7area/perimeter\u00b2 (1.0 = perfect circle).</li> <li><code>morph_eccentricity</code> - 0 (circular) to 1 (elongated).</li> <li><code>morph_solidity</code> - area / convex hull area.</li> <li><code>morph_extent</code> - area / bounding box area.</li> <li><code>morph_feret_diameter_max</code> - Maximum Feret diameter.</li> <li><code>morph_major_axis_length</code> - Major axis of fitted ellipse.</li> <li><code>morph_minor_axis_length</code> - Minor axis of fitted ellipse.</li> <li><code>morph_aspect_ratio</code> - major axis / minor axis.</li> <li><code>morph_orientation</code> - Angle in radians.</li> </ul> <p>Morphological metrics (3D images):</p> <ul> <li><code>morph_volume</code> - Volume in pixels.</li> <li><code>morph_volume_um3</code> - Volume in \u00b5m\u00b3 (if pixel sizes available).</li> <li>Limited shape descriptors (regionprops 3D limitation).</li> </ul> <p>Centroid coordinates:</p> <ul> <li>2D: <code>centroid_y</code>, <code>centroid_x</code> (pixels and \u00b5m if available).</li> <li>3D: <code>centroid_z</code>, <code>centroid_y</code>, <code>centroid_x</code> (pixels and \u00b5m if available).</li> </ul> <p>Intensity metrics (per channel):</p> <ul> <li><code>&lt;channel&gt;_mean_intensity</code> - Mean pixel intensity.</li> <li><code>&lt;channel&gt;_integrated_intensity</code> - mean \u00d7 area \u00d7 pixel_volume.</li> <li><code>&lt;channel&gt;_raw_integrated_intensity</code> - Sum of pixel values.</li> </ul> <p>Thresholded intensity (when enabled):</p> <ul> <li><code>&lt;channel&gt;_mean_intensity_thresholded</code></li> <li><code>&lt;channel&gt;_integrated_intensity_thresholded</code></li> <li><code>&lt;channel&gt;_raw_integrated_intensity_thresholded</code></li> </ul> <p>Thresholding will zero the <code>_thresholded</code> fields of cells with mean intensities outside the thresholding bounds.</p> <p>Reference columns:</p> <ul> <li><code>label_id</code> - Unique ID of the segmentation instance (a nucleus or a cytoplasm).</li> <li><code>file_path</code> - Full source path.</li> <li><code>segmentation_type</code> - \"nuclear\" or \"cytoplasmic\".</li> <li><code>overlaps_with</code> - Semicolon-separated list of overlapping labels from other segmentations in this feature, if there are multiple segmentations configured.</li> </ul> <p>ROI columns:</p> <ul> <li><code>excluded_from_roi_&lt;name&gt;</code> - 0/1 flag indicating if the cell is excluded by the named ROI.</li> <li><code>included_in_roi_&lt;name&gt;</code> - 0/1 flag indicating if the cell is included by the named ROI.</li> </ul>"},{"location":"user/quantification/#spots-feature","title":"Spots feature","text":"<p>Measures spot counts and spot-level properties from configured spot labels, with optional cell-segmentation context.</p> <p>Add channels popup:</p> <p>Segmentation section:</p> <ul> <li>Add segmentation: Add a nuclear/cytoplasmic labels layer (optional).</li> <li>Segmentation (dropdown per row): Select a cell segmentation layer.</li> <li>Delete (per row): Remove this segmentation.</li> </ul> <p>When one or more valid segmentations are configured, SenoQuant exports one pair of files (<code>*_cells</code> and <code>*_spots</code>) per segmentation.</p> <p>If no valid segmentation is configured, SenoQuant still exports all spots in a single <code>all_spots</code> file (no cells table).</p> <p>Channels section:</p> <ul> <li>Add channel: Add a spot channel row.</li> <li>Name (text): Custom channel label for output columns and colocalization labels.</li> <li>Channel (dropdown per row): Select the image layer used for spot intensity.</li> <li>Spots segmentation (dropdown per row): Select the labels layer containing spot instances for this channel.</li> <li>Delete (per row): Remove this channel.</li> </ul> <p>A channel row is exported only when both Channel and Spots segmentation are selected.</p> <p>If a selected layer is missing at runtime, the channel is skipped.</p> <p>When segmentations are configured, a channel is skipped for a segmentation if the spot-label shape does not match that segmentation shape.</p> <p>When no segmentations are configured, spot channels must share the same spot-label shape to be exported together.</p> <p>Spot labels are assigned to cells by centroid position when a segmentation is present. Spots outside segmentation are still exported and marked with <code>within_segmentation = 0</code>.</p> <p>Closing the popup or clicking Save will save the settings.</p> <p>ROI section:</p> <p>Enabled by checking the ROIs checkbox in the main feature configuration box.</p> <p>ROI controls are the same as in the Markers feature.</p> <p>Colocalization:</p> <ul> <li>Export colocalization (checkbox): Include colocalization analysis in output.</li> </ul> <p>Colocalization is computed from overlap between spot label masks across channels (not intensity correlation). This is only computed when there are at least 2 valid spot channels for a given feature.</p>"},{"location":"user/quantification/#exported-tables-spots","title":"Exported tables (Spots)","text":"<p>Cells table (one per segmentation, only when a segmentation is configured):</p> <ul> <li><code>label_id</code> - Cell label ID from the selected segmentation.</li> <li><code>centroid_&lt;axis&gt;_pixels</code> - Cell centroid in pixels (<code>y/x</code> for 2D, <code>z/y/x</code> for 3D).</li> <li><code>centroid_&lt;axis&gt;_um</code> - Cell centroid in micrometers when physical pixel sizes are available.</li> <li>Morphology columns (same naming as Markers): e.g., <code>morph_area</code>, <code>morph_volume</code>, <code>morph_*</code>.</li> <li><code>overlaps_with</code> - Semicolon-separated overlapping labels from other configured segmentations in the same feature.</li> <li>ROI columns: <code>included_in_roi_&lt;name&gt;</code> and/or <code>excluded_from_roi_&lt;name&gt;</code>.</li> <li><code>&lt;channel&gt;_spot_count</code> - Number of spots assigned to that cell for each configured channel.</li> <li><code>&lt;channel&gt;_spot_mean_intensity</code> - Mean of per-spot mean intensities for spots assigned to that cell.</li> <li><code>colocalization_event_count</code> (when enabled) - Count of unique overlapping spot pairs within the same cell.</li> </ul> <p><code>&lt;channel&gt;</code> is derived from the channel Name (or the image layer name if Name is empty), sanitized to lowercase with underscores.</p> <p>Spots table (one per segmentation, or a single <code>all_spots</code> table when no segmentation is configured):</p> <ul> <li><code>spot_id</code> - Unique identifier within channel.</li> <li><code>cell_id</code> - Parent cell label ID (0 when not assigned to a segmented cell).</li> <li><code>within_segmentation</code> - 1 when assigned to a segmented cell, 0 otherwise (present only when a segmentation is configured).</li> <li><code>channel</code> - Channel label (custom Name if provided, otherwise the image layer name).</li> <li><code>centroid_&lt;axis&gt;_pixels</code> - Spot centroid in pixels.</li> <li><code>centroid_&lt;axis&gt;_um</code> - Spot centroid in micrometers when physical pixel sizes are available.</li> <li><code>spot_area_pixels</code> (2D) or <code>spot_volume_pixels</code> (3D) - Spot size in pixel units.</li> <li><code>spot_area_um2</code> (2D) or <code>spot_volume_um3</code> (3D) - Spot size in physical units when pixel sizes are available.</li> <li><code>spot_mean_intensity</code> - Mean intensity of the spot region in the selected image channel.</li> <li>ROI columns: <code>included_in_roi_&lt;name&gt;</code> and/or <code>excluded_from_roi_&lt;name&gt;</code>, evaluated at the spot centroid.</li> <li><code>colocalizes_with</code> (when enabled) - Semicolon-separated list of overlapping spots as <code>&lt;channel_label&gt;:&lt;spot_id&gt;</code>.</li> </ul>"},{"location":"user/quantification/#output-structure","title":"Output structure","text":"<p>Results are saved to: <code>&lt;output_folder&gt;/&lt;output_name&gt;/&lt;feature_name&gt;/</code></p> <p>Each feature creates its own subfolder containing: - One file per segmentation (Markers). - Spots:   - With segmentation(s): two files per segmentation (<code>*_cells</code> and <code>*_spots</code>).   - Without segmentation: one file (<code>all_spots</code>). - <code>feature_settings.json</code> (feature configuration snapshot and run metadata).</p> <p>File naming: - Markers: <code>&lt;segmentation_label&gt;.&lt;format&gt;</code>. - Spots (with segmentation): <code>&lt;segmentation_label&gt;_cells.&lt;format&gt;</code> and <code>&lt;segmentation_label&gt;_spots.&lt;format&gt;</code>. - Spots (without segmentation): <code>all_spots.&lt;format&gt;</code>.</p>"},{"location":"user/quickstart/","title":"Quick Start","text":"<p>This guide walks through the basic workflow for analyzing senescence markers in tissue images using SenoQuant.</p>"},{"location":"user/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>napari installed with SenoQuant.</li> <li>System meets the installation requirements.</li> <li>Multi-channel microscopy image (supported formats: <code>.tif</code>, <code>.czi</code>, <code>.lif</code>, <code>.nd2</code>, etc.).</li> <li>Channels containing: Nuclei, IF markers, and/or spots.</li> </ul>"},{"location":"user/quickstart/#basic-workflow","title":"Basic workflow","text":""},{"location":"user/quickstart/#1-launch-napari-and-load-image","title":"1. Launch napari and load image","text":"<p>If you used the Installer:</p> <ul> <li>Launch SenoQuant from the Start Menu or the desktop icon.</li> </ul> <p>Manual installs (conda/uv):</p> <p>In your terminal, activate the conda environment where SenoQuant is installed and start napari:</p> <pre><code>conda activate senoquant\nnapari --with senoquant\n</code></pre> <p>Load your image:</p> <ul> <li> <p><code>File</code> \u2192 <code>Open File(s)...</code> \u2192 Select your image.</p> <p>A popup may appear for you to select the appropriate reader plugin. Choose <code>senoquant</code>.</p> </li> <li> <p>Or drag-and-drop the file into the napari window.</p> </li> </ul> <p>Expected result: Each channel appears as a separate layer in the layer list. If you're opening a multi-scene file, select the desired scene(s) from the popup.</p>"},{"location":"user/quickstart/#2-open-senoquant","title":"2. Open SenoQuant","text":"<p>SenoQuant should launch automatically in Step 1. If not:</p> <p><code>Plugins</code> \u2192 <code>SenoQuant</code></p> <p>The plugin window opens as a docked widget with 7 tabs:</p> <ul> <li>Segmentation</li> <li>Spots</li> <li>Prediction</li> <li>Quantification</li> <li>Visualization</li> <li>Batch</li> <li>Settings</li> </ul>"},{"location":"user/quickstart/#3-run-nuclear-segmentation","title":"3. Run nuclear segmentation","text":"<ol> <li>Switch to the Segmentation tab.</li> <li>In the Nuclear segmentation box, select Nuclear layer: Choose the DAPI or nuclear stain channel.</li> <li>Select Model: <code>default_2d</code> (for 2D images) or <code>default_3d</code> (for Z-stacks). <code>cpsam</code> is also available for nuclear+cytoplasmic segmentation.</li> <li> <p>Adjust model settings if needed (e.g., <code>Object diameter (px)</code>).</p> <p>To quickly estimate object diameter, create a napari Shapes layer, draw a line across a representative nucleus, then use <code>Layers</code> \u2192 <code>Measure</code> \u2192 <code>Toggle shapes dimensions measurement (napari builtins)</code>. See https://napari.org/stable/howtos/layers/shapes.html for details.</p> <p>The default settings work well for most images.</p> </li> <li> <p>Click Run.</p> </li> </ol> <p>Output: A new labels layer named <code>&lt;channel&gt;_&lt;model&gt;_nuc_labels</code> appears in the layer list.</p>"},{"location":"user/quickstart/#4-optional-run-cytoplasmic-segmentation","title":"4. (Optional) Run cytoplasmic segmentation","text":"<p>If you need to catch cytoplasmic regions for marker quantification:</p> <ol> <li>In the Segmentation tab, go to the Cytoplasmic segmentation box.</li> <li>Select Model: <code>cpsam</code>, <code>nuclear_dilation</code> or <code>perinuclear_rings</code>.</li> <li>Select image/labels layers.</li> <li>Adjust model settings if needed.</li> <li>Click Run.</li> </ol> <p>Output: A new labels layer named <code>&lt;channel&gt;_&lt;model&gt;_cyto_labels</code>.</p>"},{"location":"user/quickstart/#5-optional-detect-spots","title":"5. (Optional) Detect spots","text":"<p>If your image contains punctate spots (e.g., gH2AX, telomeres, FISH spots):</p> <ol> <li>Switch to the Spots tab.</li> <li>Select Image Layer: Choose the channel with spots.</li> <li>Select Detector: <code>rmp</code>, <code>ufish</code>.</li> <li> <p>Adjust detection settings (for example, <code>Threshold</code>).</p> <p>The default settings work well for most images.</p> </li> <li> <p>(Optional) Set Minimum diameter and Maximum diameter to filter detected spots.</p> </li> <li>Click Run.</li> </ol> <p>Output: A labels layer named <code>&lt;channel&gt;_&lt;detector&gt;_spot_labels</code>.</p>"},{"location":"user/quickstart/#6-optional-run-a-prediction-model","title":"6. (Optional) Run a prediction model","text":"<p>Use this tab for computer-vision models that predict senescence-associated feature layers.</p> <ol> <li>Switch to the Prediction tab.</li> <li>Select Select model: <code>demo_model</code> (current placeholder).</li> <li>In Model interface:</li> <li>Select Image layer.</li> <li>Set Multiplier.</li> <li>Click Run.</li> </ol> <p>Output: A new image layer named <code>&lt;image layer&gt;_demo_model</code>.</p>"},{"location":"user/quickstart/#7-configure-quantification-features","title":"7. Configure quantification features","text":"<p>The quantification tab organizes exports by Features. A feature defines what to quantify and how. In the current version, two feature types are supported: Markers and Spots. This is based on common data types in senescence research:</p> <ul> <li>Markers: Measure intensity-based markers (e.g., IF markers) within nuclear/cytoplasmic masks.</li> <li>Spots: Count spots and analyze colocalization within cell masks.</li> </ul> <p>To add a feature:</p> <ol> <li>Switch to the Quantification tab.</li> <li> <p>Click Add feature \u2192 Select feature Type:</p> <ul> <li>Markers: For intensity-based IF marker quantification.</li> <li>Spots: For spot counting and colocalization.</li> </ul> </li> <li> <p>Name your feature (e.g., <code>IF markers</code>, <code>IF spots</code>).</p> </li> </ol>"},{"location":"user/quickstart/#configure-a-markers-feature","title":"Configure a Markers feature","text":"<ol> <li>Click Add channels.</li> <li> <p>In the popup:</p> <ul> <li> <p>In the top Segmentations box, click Add segmentation \u2192 Add nuclear/cytoplasmic labels layer.</p> <p>The selected segmentation defines the nuclei/cells for quantification. SenoQuant will export one cell x marker table per segmentation.</p> </li> <li> <p>In the Channels box, click Add channel \u2192 Add intensity channel(s) to quantify.</p> </li> <li>For each channel, name the channel (e.g., <code>DAPI</code>, <code>p16</code>), and select the image layer containing the marker. Optionally, click the Set threshold checkbox to define an intensity threshold for positive/negative calls automatically or manually. The threshold sliders are linked to the napari layer contrast limits for easy visualization.</li> <li>Click Save or close the popup when done.</li> </ul> </li> <li> <p>(Optional) Draw ROIs with a shapes layer. Enable ROIs \u2192 Name the ROI \u2192 Select the shapes layer. Select the ROI Type to be <code>Include</code> or <code>Exclude</code>. Nuclei/cells inside <code>Include</code> ROIs or outside <code>Exclude</code> ROIs will be marked in the output table.</p> </li> </ol>"},{"location":"user/quickstart/#configure-a-spots-feature","title":"Configure a Spots feature","text":"<ol> <li>Click Add channels.</li> <li> <p>In the popup:</p> <ul> <li> <p>(Optional) In the top box, click Add segmentation \u2192 Add a nuclear/cytoplasmic labels layer if you want per-cell spot summaries.</p> <p>With segmentation(s), SenoQuant exports one <code>*_cells</code> + <code>*_spots</code> table pair per segmentation. Without segmentation, it still exports all spots in <code>all_spots</code>.</p> </li> <li> <p>In the Channels box, click Add channel \u2192 Add spot channel(s) to quantify.</p> </li> <li>For each channel, name the channel (e.g., <code>gH2AX</code>, <code>Telomere</code>), select the image layer in Channel, and select the corresponding spot-label layer generated in the Spots tab under Spots segmentation.</li> <li>Click Save or close the popup when done.</li> </ul> </li> <li> <p>(Optional) Enable ROIs \u2192 Name the ROI \u2192 Select the shapes layer. ROIs work the same way as in the Markers feature.</p> </li> <li>(Optional) Enable Export colocalization to analyze spot colocalization between two or more spot channels. Colocalization will only be computed if two or more spot channels are added to the feature.</li> </ol>"},{"location":"user/quickstart/#8-run-quantification","title":"8. Run quantification","text":"<ol> <li>In the Quantification tab, ensure all features are configured</li> <li>In the Output box, browse to select an output folder.</li> <li>Name the quantification run in Save name.</li> <li>Choose Format: <code>xlsx</code> (Excel) or <code>csv</code>.</li> <li>Click Process and save.</li> <li>Wait for quantification to complete.</li> </ol> <p>Outputs:  Excel/CSV files containing:</p> <ul> <li>Markers: Marker intensities per cell, morphological features.</li> <li>Spots: Spot counts per cell, spot intensities, colocalization data (if enabled).</li> </ul> <p>Segmentation masks are also saved, plus a <code>.json</code> file with the configuration used for the run.</p>"},{"location":"user/quickstart/#batch-processing-workflow","title":"Batch processing workflow","text":"<p>For high-throughput analysis of multiple images:</p>"},{"location":"user/quickstart/#1-open-the-batch-tab","title":"1. Open the Batch tab","text":"<p>In the SenoQuant dock widget, select Batch.</p>"},{"location":"user/quickstart/#2-configure-inputs","title":"2. Configure inputs","text":"<ol> <li>Input folder \u2192 Choose the directory containing images.</li> <li>Extensions \u2192 List the file types to include (e.g., <code>.tif, .nd2, .czi</code>).</li> <li>(Optional) Include subfolders \u2192 Enable if your data are nested.</li> <li>(Optional) Process all scenes \u2192 Enable for multi-scene files.</li> </ol>"},{"location":"user/quickstart/#3-map-channels","title":"3. Map channels","text":"<p>Add channel names and indices so they appear in all dropdowns:</p> <ul> <li>Name: <code>DAPI</code>, <code>FITC</code>, <code>Cy3</code>, etc.</li> <li>Index: zero-based channel index</li> </ul>"},{"location":"user/quickstart/#4-enable-processing-steps","title":"4. Enable processing steps","text":"<p>Configure only the steps you need:</p> <ul> <li>Nuclear segmentation \u2192 Enable, select model and channel, adjust settings.</li> <li>Cytoplasmic segmentation (optional) \u2192 Enable if needed.</li> <li>Spot detection (optional) \u2192 Choose detector and channels; set min/max diameter-style filtering if needed.</li> </ul>"},{"location":"user/quickstart/#5-configure-quantification-optional","title":"5. Configure quantification (optional)","text":"<p>If you want batch exports:</p> <ol> <li>Enable Quantification.</li> <li>Click Add feature and set up Markers or Spots features as in the single-image workflow.</li> </ol> <p>Note: ROI selection and threshold tuning are not available in batch mode.</p>"},{"location":"user/quickstart/#6-set-outputs-and-run","title":"6. Set outputs and run","text":"<ol> <li>Output folder \u2192 Choose where results are written.</li> <li>(Optional) Overwrite \u2192 Enable to replace existing outputs.</li> <li>Click Run batch.</li> </ol> <p>Outputs: Each input image gets its own output folder with (if enabled) quantification tables plus per-feature <code>feature_settings.json</code> metadata files. Masks are also saved. The batch output root includes a <code>senoquant_settings.json</code> file with the batch configuration used for the run.</p>"},{"location":"user/quickstart/#settings-persistence-recommended","title":"Settings persistence (recommended)","text":"<p>Before closing napari, save your configuration:</p> <ol> <li>Open the Settings tab.</li> <li>Click Save settings and store <code>senoquant_settings.json</code>.</li> </ol> <p>To continue later, click Load settings in the same tab. If the JSON contains batch configuration, the Batch tab is populated too.</p>"},{"location":"user/quickstart/#next-steps","title":"Next steps","text":"<ul> <li>Segmentation - Detailed model settings and parameters</li> <li>Spots - Advanced spot detection configuration</li> <li>Prediction - Prediction model workflow and placeholder example</li> <li>Quantification - Feature export details and column definitions</li> <li>Visualization - Plot generation from quantification tables</li> <li>Batch - Batch processing and automation</li> <li>Data - Supported file formats and metadata handling</li> </ul>"},{"location":"user/segmentation/","title":"Segmentation","text":"<p>The Segmentation tab provides two sections for segmenting nuclei and cytoplasm in your images.</p>"},{"location":"user/segmentation/#interface-overview","title":"Interface overview","text":""},{"location":"user/segmentation/#nuclear-segmentation-section","title":"Nuclear segmentation section","text":"<p>Controls:</p> <ul> <li>Nuclear layer (dropdown): Select the image layer containing nuclear staining.</li> <li>Model (dropdown): Choose a nuclear segmentation model.</li> <li>Settings (dynamic panel): Model-specific parameters that update based on selected model.</li> <li>Run (button): Execute nuclear segmentation on the selected image.</li> </ul>"},{"location":"user/segmentation/#cytoplasmic-segmentation-section","title":"Cytoplasmic segmentation section","text":"<p>Controls:</p> <ul> <li>Cytoplasmic layer (dropdown): Select the image layer containing cytoplasmic staining.</li> <li>Nuclear layer (dropdown): Optional nuclear segmentation mask (required for some models).</li> <li>Model (dropdown): Choose a cytoplasmic segmentation model.</li> <li>Settings (dynamic panel): Model-specific parameters.</li> <li>Run (button): Execute cytoplasmic segmentation.</li> </ul>"},{"location":"user/segmentation/#available-models","title":"Available models","text":""},{"location":"user/segmentation/#nuclear-segmentation-models","title":"Nuclear segmentation models","text":"Model Description Dimensionality <code>default_2d</code> Fine-tuned StarDist model for 2D nuclei. 2D <code>default_3d</code> Fine-tuned StarDist model for 3D nuclei. 3D <code>cpsam</code> Cellpose SAM model for nuclei. 2D/3D"},{"location":"user/segmentation/#cytoplasmic-segmentation-models","title":"Cytoplasmic segmentation models","text":"Model Description Input requirements Use case <code>cpsam</code> Cellpose SAM cytoplasmic. Cytoplasm image (nuclear optional). General cytoplasm segmentation. <code>nuclear_dilation</code> Dilates nuclear masks. Nuclear mask only. Weak or missing cytoplasmic staining. <code>perinuclear_rings</code> For ring-shaped regions. Nuclear mask only. Perinuclear marker analysis."},{"location":"user/segmentation/#output-layers","title":"Output layers","text":"<ul> <li>Nuclear segmentation outputs <code>&lt;image layer&gt;_&lt;model&gt;_nuc_labels</code>.</li> <li>Cytoplasmic segmentation outputs <code>&lt;image layer&gt;_&lt;model&gt;_cyto_labels</code>.</li> </ul>"},{"location":"user/segmentation/#preloading-models","title":"Preloading models","text":"<p>SenoQuant instantiates discovered segmentation models when the tab loads. This reduces first-run latency for model execution.</p>"},{"location":"user/segmentation/#settings-reference","title":"Settings reference","text":"<p>This section mirrors the model metadata in the plugin. Use it as a guide for choosing the right model and tuning its parameters.</p>"},{"location":"user/segmentation/#default_2d-stardist-2d","title":"default_2d (StarDist 2D)","text":"<p>Best for: 2D nuclei with clear boundaries (single z-slice or 2D projections).</p> <p>How it works: StarDist predicts star-convex polygons around nuclei and uses non-maximum suppression to separate instances.</p> Setting Type Default Range Description Object diameter (px) float 30.0 1.0 - 500.0 Expected diameter of nuclei in pixels. Adjust as needed. Prob threshold float 0.496 0.0 - 1.0 Confidence threshold for accepting nuclei. Lower detects more, higher is stricter. NMS threshold float 0.3 0.0 - 1.0 Non-maximum suppression threshold for separating instances. Lower splits more. <p>Normalization is always applied internally using percentile clipping (<code>pmin=1.0</code>, <code>pmax=99.8</code>) and is not exposed in the UI.</p>"},{"location":"user/segmentation/#default_3d-stardist-3d","title":"default_3d (StarDist 3D)","text":"<p>Best for: 3D stacks where nuclei extend across multiple z-planes.</p> <p>How it works: StarDist 3D predicts star-convex polyhedra in volumetric data.</p> Setting Type Default Range Description Object diameter (px) float 30.0 1.0 - 500.0 Expected diameter of nuclei in pixels. Prob threshold float 0.445 0.0 - 1.0 Confidence threshold for accepting nuclei. NMS threshold float 0.3 0.0 - 1.0 Non-maximum suppression threshold for separating instances. <p>Normalization is always applied internally using percentile clipping (<code>pmin=1.0</code>, <code>pmax=99.8</code>) and is not exposed in the UI.</p>"},{"location":"user/segmentation/#cpsam-cellpose-sam","title":"cpsam (Cellpose SAM)","text":"<p>Best for: General purpose nuclear/cytoplasmic segmentation.</p> <p>How it works: Cellpose with SAM encoder.</p> Setting Type Default Range Description Object diameter (px) float 30.0 0.1 - 1000.0 Expected diameter of cells or nuclei. Flow threshold float 0.4 0.0 - 2.0 Maximum allowed flow error; lower is stricter, higher accepts more masks. Cellprob threshold float 0.0 -6.0 - 6.0 Threshold on cell probability; Higher = accept fewer masks. Number of iterations int 0 0 - 9999 Iterations of dynamic simulation (0 = automatic; For larger/longer cells, try a higher value like 2000). <p>For CPSAM, dimensionality is auto-detected from the selected image (<code>2D</code> vs <code>3D</code>) and normalization is always enabled internally.</p>"},{"location":"user/segmentation/#nuclear_dilation-cytoplasmic","title":"nuclear_dilation (Cytoplasmic)","text":"<p>Best for: Approximating cytoplasm when you only have nuclear masks.</p> <p>How it works: Binary dilation expands nuclear labels outward by a fixed number of pixels.</p> Setting Type Default Range Description Dilation iterations int 5 1 - 100 Number of binary dilation iterations to expand nuclear masks."},{"location":"user/segmentation/#perinuclear_rings-cytoplasmic","title":"perinuclear_rings (Cytoplasmic)","text":"<p>Best for: Perinuclear marker quantification (eg., nuclear envelope).</p> <p>How it works: Erodes nuclei inward and dilates outward to form a ring mask.</p> Setting Type Default Range Description Inner erosion (px) int 2 1 - 50 Pixels to erode inward from the nuclear boundary. Outer dilation (px) int 5 0 - 50 Pixels to dilate outward from the nuclear boundary. <p>Note: The minimum inner erosion is set to 1 pixel as needed by the logic to associate across segmentation masks in Quantification.</p>"},{"location":"user/settings/","title":"Settings","text":"<p>The Settings tab is the central place for persisting and reloading analysis configuration across tabs.</p> <p>It uses a unified JSON bundle (<code>senoquant_settings.json</code>) so the same file format can be reused by:</p> <ul> <li>Manual save/load from the Settings tab.</li> <li>Batch output metadata generated after batch runs.</li> <li>Quantification feature exports that include settings context.</li> </ul>"},{"location":"user/settings/#controls","title":"Controls","text":"<ul> <li>Save settings: Writes a <code>senoquant_settings.json</code> file.</li> <li>Load settings: Reads a <code>senoquant_settings.json</code> file and applies   supported settings.</li> </ul>"},{"location":"user/settings/#what-is-saved","title":"What is saved","text":""},{"location":"user/settings/#segmentation-tab-state","title":"Segmentation tab state","text":"<ul> <li>Selected nuclear model.</li> <li>Current nuclear model settings.</li> <li>Selected cytoplasmic model.</li> <li>Current cytoplasmic model settings.</li> </ul>"},{"location":"user/settings/#spots-tab-state","title":"Spots tab state","text":"<ul> <li>Selected detector.</li> <li>Current detector settings.</li> <li>Spot diameter filters (minimum and maximum diameter values in pixels).</li> </ul>"},{"location":"user/settings/#batch-tab-state","title":"Batch tab state","text":"<ul> <li>Current batch configuration is saved into the bundle under <code>batch_job</code>.</li> <li>This allows the same file to restore batch UI state later.</li> </ul>"},{"location":"user/settings/#bundle-key-layout","title":"Bundle key layout","text":"<ul> <li>Segmentation + Spots UI state is stored under <code>tab_settings</code>.</li> <li>Batch UI state is stored under <code>batch_job</code>.</li> <li>Quantification feature exports use separate per-feature <code>feature_settings.json</code>   files and are not intended for Settings-tab reload.</li> </ul>"},{"location":"user/settings/#what-is-restored-on-load","title":"What is restored on load","text":"<ul> <li>Segmentation model selections and settings.</li> <li>Spots detector settings and diameter filters.</li> <li>Batch tab state, when the loaded JSON contains a non-empty <code>batch_job</code>   section.</li> </ul>"},{"location":"user/settings/#what-is-not-restored","title":"What is not restored","text":"<ul> <li>Prediction tab model selection and model-interface settings.</li> <li>Quantification tab feature configuration.</li> <li>Visualization tab plot configuration.</li> <li>Runtime viewer state (active layer selection, visibility, colormaps).</li> </ul>"},{"location":"user/settings/#typical-workflow","title":"Typical workflow","text":"<ol> <li>Configure Segmentation and Spots parameters in their tabs.</li> <li>Optionally configure Batch settings.</li> <li>Open Settings and click Save settings.</li> <li>Reopen later and click Load settings to restore the saved setup.</li> </ol>"},{"location":"user/settings/#notes","title":"Notes","text":"<ul> <li>The UI stores and restores settings by key, so unknown keys in a JSON file   are ignored safely.</li> <li>If a model or detector from the file is unavailable in the current   installation, that specific selection cannot be applied.</li> </ul>"},{"location":"user/spots/","title":"Spots","text":"<p>The Spots tab provides spot detection and colocalization visualization for analyzing fluorescent spots in your images.</p>"},{"location":"user/spots/#interface-overview","title":"Interface overview","text":""},{"location":"user/spots/#spot-detection-section","title":"Spot detection section","text":"<p>Controls:</p> <ul> <li>Image layer (dropdown): Select the image layer containing spots to detect.</li> <li>Detector (dropdown): Choose a spot detection algorithm.</li> <li>Settings (dynamic panel): Detector-specific parameters.</li> <li>Minimum diameter (spin box): Minimum spot diameter in pixels (<code>0</code> = no minimum filter).</li> <li>Maximum diameter (spin box): Maximum spot diameter in pixels (<code>0</code> = no maximum filter).</li> <li>Run (button): Execute spot detection on the selected image.</li> </ul> <p>Diameter filtering behavior: After detection, connected components are filtered against diameter-derived thresholds:</p> <ul> <li>For 2D labels, thresholds are converted to effective area: <code>A = pi * (d / 2)^2</code>.</li> <li>For 3D labels, thresholds are converted to effective volume: <code>V = (4/3) * pi * (d / 2)^3</code>.</li> </ul> <p>Components with pixel/voxel counts outside the computed range are removed.</p>"},{"location":"user/spots/#colocalization-section","title":"Colocalization section","text":"<p>Controls:</p> <ul> <li>Labels A (dropdown): First labels layer.</li> <li>Labels B (dropdown): Second labels layer.</li> <li>Visualize (button): Compute intersection and visualize overlaps.</li> </ul> <p>Output: Creates a Points layer named <code>{labels_A}_{labels_B}_colocalization</code> with yellow ring markers at overlap locations.</p>"},{"location":"user/spots/#available-detectors","title":"Available detectors","text":"Detector Algorithm Description <code>rmp</code> Rotational Morphological Processing (RMP) Spot extraction with rotating images and thin structuring elements. Compatible with 2D and 3D images. <code>ufish</code> U-FISH Spot extraction with a compact deep learning model for 2D and 3D images."},{"location":"user/spots/#output-layers","title":"Output layers","text":"<ul> <li>Spot detection outputs <code>&lt;image layer&gt;_&lt;detector&gt;_spot_labels</code>.</li> </ul>"},{"location":"user/spots/#detector-settings","title":"Detector settings","text":""},{"location":"user/spots/#rmp","title":"rmp","text":"<p>Source: <code>src/senoquant/tabs/spots/models/rmp/details.json</code> and <code>src/senoquant/tabs/spots/models/rmp/model.py</code>.  </p> <p>Method reference: Rotational Morphological Processing for spot detection.</p> Setting Type Default Range Description Spot diameter (px) int 10 3 - 9999 Expected spot diameter used by the extraction structuring element. Auto threshold bool true n/a Uses Otsu thresholding on the normalized response. Manual threshold float 0.50 0.0 - 1.0 Fixed threshold when Auto threshold is off. Disabled when auto-thresholding is enabled. <p>RMP simplifications: - Angle spacing is fixed internally to <code>5</code> degrees. - Wavelet denoising is always enabled (both before and after top-hat extraction).</p>"},{"location":"user/spots/#ufish","title":"ufish","text":"<p>Source: <code>src/senoquant/tabs/spots/models/ufish/details.json</code> and <code>src/senoquant/tabs/spots/models/ufish/model.py</code>.</p> Setting Type Default Range Description Spot size float 1.0 0.25 - 4.0 Spot-scale control. <code>1.0</code> is default, <code>&gt;1</code> biases detection toward larger spots, <code>&lt;1</code> toward smaller spots. Threshold float 0.5 0.0 - 1.0 Foreground threshold on the enhanced response (lower = more spots). <p>UFISH simplification: - Wavelet denoising is always enabled before enhancement/segmentation.</p>"},{"location":"user/visualization/","title":"Visualization","text":"<p>The Visualization tab generates summary plots from quantification exports.</p>"},{"location":"user/visualization/#interface-overview","title":"Interface overview","text":""},{"location":"user/visualization/#input-section","title":"Input section","text":"<p>Controls:</p> <ul> <li>Input folder (browse field): Folder containing quantification tables (<code>.csv</code>, <code>.xlsx</code>, <code>.xls</code>).</li> <li>Extensions (text field): File extensions to search for in the input folder.</li> </ul> <p>Behavior notes:</p> <ul> <li>SenoQuant reads the first matching table to discover marker columns.</li> <li>Marker columns are detected from headers ending with <code>_mean_intensity</code>.</li> <li>If a JSON file is present, threshold values are auto-loaded when possible.</li> </ul>"},{"location":"user/visualization/#marker-selection-and-thresholding-section","title":"Marker selection and thresholding section","text":"<p>Controls:</p> <ul> <li>Select all / Deselect all (buttons): Toggle all marker include checkboxes.</li> <li>Include (checkbox per row): Include marker in downstream plotting.</li> <li>Marker (read-only): Marker name parsed from quantification columns.</li> <li>Threshold (text field per row): Optional threshold value for each marker.</li> </ul> <p>Behavior notes:</p> <ul> <li>Thresholds are applied per marker before plotting.</li> <li>Empty threshold values are treated as automatic/no override.</li> </ul>"},{"location":"user/visualization/#plots-section","title":"Plots section","text":"<p>Controls:</p> <ul> <li>Plot type (dropdown): Select the visualization type.</li> </ul> <p>Available plot types:</p> <ul> <li>Spatial Plot</li> <li>UMAP</li> <li>Double Expression</li> </ul>"},{"location":"user/visualization/#plot-preview-section","title":"Plot preview section","text":"<p>Controls:</p> <ul> <li>Process (button): Generate preview outputs using current settings.</li> </ul> <p>Behavior notes:</p> <ul> <li>PNG plots are shown directly in the preview pane.</li> <li>SVG and PDF plots are shown as clickable links.</li> <li>Running Process again clears previous previews.</li> </ul>"},{"location":"user/visualization/#output-section","title":"Output section","text":"<p>Controls:</p> <ul> <li>Output path (browse field): Destination folder for saved plots.</li> <li>Plot name (text field): Base name for saved files.</li> <li>Format (dropdown): <code>png</code>, <code>svg</code>, or <code>pdf</code>.</li> <li>Save plot (button): Copy the latest processed plots to the output folder.</li> </ul>"},{"location":"user/visualization/#plot-behavior-details","title":"Plot behavior details","text":""},{"location":"user/visualization/#spatial-plot","title":"Spatial Plot","text":"<ul> <li>Uses detected X/Y coordinate columns for point positions.</li> <li>Colors by the first numeric column that is not X or Y.</li> <li>Marker filtering keeps selected marker intensity columns and drops deselected marker intensity columns.</li> </ul>"},{"location":"user/visualization/#umap","title":"UMAP","text":"<ul> <li>Uses selected marker intensity columns as UMAP input features.</li> <li>Requires at least two numeric input columns.</li> <li>Generates a 2D embedding scatter plot.</li> </ul>"},{"location":"user/visualization/#double-expression","title":"Double Expression","text":"<ul> <li>Requires exactly two selected markers.</li> <li>Uses thresholds for each selected marker.</li> <li>Draws:</li> <li>Negative cells (background, light gray).</li> <li>Marker 1 positive only (red).</li> <li>Marker 2 positive only (blue).</li> <li>Double positive (green).</li> </ul>"},{"location":"user/visualization/#output-naming","title":"Output naming","text":"<ul> <li>If Plot name is set and a single output is produced, filename is <code>&lt;plot_name&gt;.&lt;ext&gt;</code>.</li> <li>If multiple outputs are produced, filenames are <code>&lt;plot_name&gt;_1.&lt;ext&gt;</code>, <code>&lt;plot_name&gt;_2.&lt;ext&gt;</code>, etc.</li> <li>If Plot name is blank, SenoQuant prefixes filenames with the plot type.</li> </ul>"},{"location":"user/visualization/#tips","title":"Tips","text":"<ul> <li>Use quantification outputs from the same image cohort for consistent marker columns.</li> <li>Check X/Y coordinate column names in your exported tables if spatial plots return no output.</li> <li>For Double Expression, make sure both selected markers exist as <code>&lt;marker&gt;_mean_intensity</code>.</li> </ul>"}]}